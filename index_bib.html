<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
<title>index.bib</title>
</head>

<body>
<h1>index.bib</h1><a name="ramachandran17_swish"></a><pre>
@article{<a href="index.html#ramachandran17_swish">ramachandran17_swish</a>,
  author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc
                  V.},
  title = {Swish: a Self-Gated Activation Function},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.05941v1">http://arxiv.org/abs/1710.05941v1</a>},
  abstract = {The choice of activation functions in deep networks
                  has a significant effect on the training dynamics
                  and task performance. Currently, the most successful
                  and widely-used activation function is the Rectified
                  Linear Unit (ReLU). Although various alternatives to
                  ReLU have been proposed, none have managed to
                  replace it due to inconsistent gains. In this work,
                  we propose a new activation function, named Swish,
                  which is simply $f(x) = x \cdot \text{sigmoid}(x)$.
                  Our experiments show that Swish tends to work better
                  than ReLU on deeper models across a number of
                  challenging datasets. For example, simply replacing
                  ReLUs with Swish units improves top-1 classification
                  accuracy on ImageNet by 0.9 \% for Mobile NASNet-A
                  and 0.6 \% for Inception-ResNet-v2. The simplicity
                  of Swish and its similarity to ReLU make it easy for
                  practitioners to replace ReLUs with Swish units in
                  any neural network.},
  archiveprefix = {arXiv},
  eprint = {1710.05941},
  primaryclass = {cs.NE}
}
</pre>

<a name="liu17_relat_pins_at_pinter"></a><pre>
@article{<a href="index.html#liu17_relat_pins_at_pinter">liu17_relat_pins_at_pinter</a>,
  author = {Liu, David C. and Rogers, Stephanie and Shiau,
                  Raymond and Kislyuk, Dmitry and Ma, Kevin C. and
                  Zhong, Zhigang and Liu, Jenny and Jing, Yushi},
  title = {Related Pins At Pinterest: The Evolution of a
                  Real-World Recommender System},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1702.07969v1">http://arxiv.org/abs/1702.07969v1</a>},
  abstract = {Related Pins is the Web-scale recommender system
                  that powers over 40 \% of user engagement on
                  Pinterest. This paper is a longitudinal study of
                  three years of its development, exploring the
                  evolution of the system and its components from
                  prototypes to present state. Each component was
                  originally built with many constraints on
                  engineering effort and computational resources, so
                  we prioritized the simplest and highest-leverage
                  solutions. We show how organic growth led to a
                  complex system and how we managed this complexity.
                  Many challenges arose while building this system,
                  such as avoiding feedback loops, evaluating
                  performance, activating content, and eliminating
                  legacy heuristics. Finally, we offer suggestions for
                  tackling these challenges when engineering Web-scale
                  recommender systems.},
  archiveprefix = {arXiv},
  eprint = {1702.07969},
  primaryclass = {cs.IR}
}
</pre>

<a name="henderson17_effic_natur_languag_respon_sugges_smart_reply"></a><pre>
@article{<a href="index.html#henderson17_effic_natur_languag_respon_sugges_smart_reply">henderson17_effic_natur_languag_respon_sugges_smart_reply</a>,
  author = {Henderson, Matthew and Al-Rfou, Rami and Strope,
                  Brian and Sung, Yun-hsuan and Lukacs, Laszlo and
                  Guo, Ruiqi and Kumar, Sanjiv and Miklos, Balint and
                  Kurzweil, Ray},
  title = {Efficient Natural Language Response Suggestion for
                  Smart Reply},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1705.00652v1">http://arxiv.org/abs/1705.00652v1</a>},
  abstract = {This paper presents a computationally efficient
                  machine-learned method for natural language response
                  suggestion. Feed-forward neural networks using
                  n-gram embedding features encode messages into
                  vectors which are optimized to give message-response
                  pairs a high dot-product value. An optimized search
                  finds response suggestions. The method is evaluated
                  in a large-scale commercial e-mail application,
                  Inbox by Gmail. Compared to a sequence-to-sequence
                  approach, the new system achieves the same quality
                  at a small fraction of the computational
                  requirements and latency.},
  archiveprefix = {arXiv},
  eprint = {1705.00652},
  primaryclass = {cs.CL}
}
</pre>

<a name="mahendran14_under_deep_image_repres_by_inver_them"></a><pre>
@article{<a href="index.html#mahendran14_under_deep_image_repres_by_inver_them">mahendran14_under_deep_image_repres_by_inver_them</a>,
  author = {Mahendran, Aravindh and Vedaldi, Andrea},
  title = {Understanding Deep Image Representations By
                  Inverting Them},
  journal = {CoRR},
  year = 2014,
  url = {<a href="http://arxiv.org/abs/1412.0035v1">http://arxiv.org/abs/1412.0035v1</a>},
  abstract = {Image representations, from SIFT and Bag of Visual
                  Words to Convolutional Neural Networks (CNNs), are a
                  crucial component of almost any image understanding
                  system. Nevertheless, our understanding of them
                  remains limited. In this paper we conduct a direct
                  analysis of the visual information contained in
                  representations by asking the following question:
                  given an encoding of an image, to which extent is it
                  possible to reconstruct the image itself? To answer
                  this question we contribute a general framework to
                  invert representations. We show that this method can
                  invert representations such as HOG and SIFT more
                  accurately than recent alternatives while being
                  applicable to CNNs too. We then use this technique
                  to study the inverse of recent state-of-the-art CNN
                  image representations for the first time. Among our
                  findings, we show that several layers in CNNs retain
                  photographically accurate information about the
                  image, with different degrees of geometric and
                  photometric invariance.},
  archiveprefix = {arXiv},
  eprint = {1412.0035},
  primaryclass = {cs.CV}
}
</pre>

<a name="gatys15_textur_synth_using_convol_neural_networ"></a><pre>
@article{<a href="index.html#gatys15_textur_synth_using_convol_neural_networ">gatys15_textur_synth_using_convol_neural_networ</a>,
  author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge,
                  Matthias},
  title = {Texture Synthesis Using Convolutional Neural
                  Networks},
  journal = {CoRR},
  year = 2015,
  url = {<a href="http://arxiv.org/abs/1505.07376v3">http://arxiv.org/abs/1505.07376v3</a>},
  abstract = {Here we introduce a new model of natural textures
                  based on the feature spaces of convolutional neural
                  networks optimised for object recognition. Samples
                  from the model are of high perceptual quality
                  demonstrating the generative power of neural
                  networks trained in a purely discriminative fashion.
                  Within the model, textures are represented by the
                  correlations between feature maps in several layers
                  of the network. We show that across layers the
                  texture representations increasingly capture the
                  statistical properties of natural images while
                  making object information more and more explicit.
                  The model provides a new tool to generate stimuli
                  for neuroscience and might offer insights into the
                  deep representations learned by convolutional neural
                  networks.},
  archiveprefix = {arXiv},
  eprint = {1505.07376},
  primaryclass = {cs.CV}
}
</pre>

<a name="christiano-2017-deep-reinf"></a><pre>
@article{<a href="index.html#christiano-2017-deep-reinf">christiano-2017-deep-reinf</a>,
  author = {Christiano, Paul and Leike, Jan and Brown, Tom B.
                  and Martic, Miljan and Legg, Shane and Amodei,
                  Dario},
  title = {Deep Reinforcement Learning From Human Preferences},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1706.03741v3">http://arxiv.org/abs/1706.03741v3</a>},
  abstract = {For sophisticated reinforcement learning (RL)
                  systems to interact usefully with real-world
                  environments, we need to communicate complex goals
                  to these systems. In this work, we explore goals
                  defined in terms of (non-expert) human preferences
                  between pairs of trajectory segments. We show that
                  this approach can effectively solve complex RL tasks
                  without access to the reward function, including
                  Atari games and simulated robot locomotion, while
                  providing feedback on less than one percent of our
                  agent's interactions with the environment. This
                  reduces the cost of human oversight far enough that
                  it can be practically applied to state-of-the-art RL
                  systems. To demonstrate the flexibility of our
                  approach, we show that we can successfully train
                  complex novel behaviors with about an hour of human
                  time. These behaviors and environments are
                  considerably more complex than any that have been
                  previously learned from human feedback.},
  archiveprefix = {arXiv},
  eprint = {1706.03741},
  primaryclass = {stat.ML}
}
</pre>

<a name="smith-2017-under-gener"></a><pre>
@article{<a href="index.html#smith-2017-under-gener">smith-2017-under-gener</a>,
  author = {Smith, Samuel L. and Le, Quoc V.},
  title = {Understanding Generalization and Stochastic Gradient
                  Descent},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.06451v1">http://arxiv.org/abs/1710.06451v1</a>},
  abstract = {This paper tackles two related questions at the
                  heart of machine learning; how can we predict if a
                  minimum will generalize to the test set, and why
                  does stochastic gradient descent find minima that
                  generalize well? Our work is inspired by Zhang et
                  al. (2017), who showed deep networks can easily
                  memorize randomly labeled training data, despite
                  generalizing well when shown real labels of the same
                  inputs. We show here that the same phenomenon occurs
                  in small linear models. These observations are
                  explained by evaluating the Bayesian evidence in
                  favor of each model, which penalizes sharp minima.
                  Next, we explore the "generalization gap" between
                  small and large batch training, identifying an
                  optimum batch size which maximizes the test set
                  accuracy. Noise in the gradient updates is
                  beneficial, driving the dynamics towards robust
                  minima for which the evidence is large. Interpreting
                  stochastic gradient descent as a stochastic
                  differential equation, we predict the optimum batch
                  size is proportional to both the learning rate and
                  the size of the training set, and verify these
                  predictions empirically.},
  archiveprefix = {arXiv},
  eprint = {1710.06451},
  primaryclass = {cs.LG}
}
</pre>

<a name="alsallakh-2017-do-convol"></a><pre>
@article{<a href="index.html#alsallakh-2017-do-convol">alsallakh-2017-do-convol</a>,
  author = {Alsallakh, Bilal and Jourabloo, Amin and Ye, Mao and
                  Liu, Xiaoming and Ren, Liu},
  title = {Do Convolutional Neural Networks Learn Class
                  Hierarchy?},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.06501v1">http://arxiv.org/abs/1710.06501v1</a>},
  abstract = {Convolutional Neural Networks (CNNs) currently
                  achieve state-of-the-art accuracy in image
                  classification. With a growing number of classes,
                  the accuracy usually drops as the possibilities of
                  confusion increase. Interestingly, the class
                  confusion patterns follow a hierarchical structure
                  over the classes. We present visual-analytics
                  methods to reveal and analyze this hierarchy of
                  similar classes in relation with CNN-internal data.
                  We found that this hierarchy not only dictates the
                  confusion patterns between the classes, it
                  furthermore dictates the learning behavior of CNNs.
                  In particular, the early layers in these networks
                  develop feature detectors that can separate
                  high-level groups of classes quite well, even after
                  a few training epochs. In contrast, the latter
                  layers require substantially more epochs to develop
                  specialized feature detectors that can separate
                  individual classes. We demonstrate how these
                  insights are key to significant improvement in
                  accuracy by designing hierarchy-aware CNNs that
                  accelerate model convergence and alleviate
                  overfitting. We further demonstrate how our methods
                  help in identifying various quality issues in the
                  training data.},
  archiveprefix = {arXiv},
  eprint = {1710.06501},
  primaryclass = {cs.CV}
}
</pre>

<a name="holden-2017-phasefunctionnn"></a><pre>
@misc{<a href="index.html#holden-2017-phasefunctionnn">holden-2017-phasefunctionnn</a>,
  url = {<a href="http://theorangeduck.com/media/uploads/other_stuff/phasefunction.pdf">http://theorangeduck.com/media/uploads/other_stuff/phasefunction.pdf</a>},
  note = {Last accessed Fri Oct 27 09:30:15 2017}
}
</pre>

<a name="moosavi-dezfooli-2016-univer-adver-pertur"></a><pre>
@article{<a href="index.html#moosavi-dezfooli-2016-univer-adver-pertur">moosavi-dezfooli-2016-univer-adver-pertur</a>,
  author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein
                  and Fawzi, Omar and Frossard, Pascal},
  title = {Universal Adversarial Perturbations},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1610.08401v3">http://arxiv.org/abs/1610.08401v3</a>},
  abstract = {Given a state-of-the-art deep neural network
                  classifier, we show the existence of a universal
                  (image-agnostic) and very small perturbation vector
                  that causes natural images to be misclassified with
                  high probability. We propose a systematic algorithm
                  for computing universal perturbations, and show that
                  state-of-the-art deep neural networks are highly
                  vulnerable to such perturbations, albeit being
                  quasi-imperceptible to the human eye. We further
                  empirically analyze these universal perturbations
                  and show, in particular, that they generalize very
                  well across neural networks. The surprising
                  existence of universal perturbations reveals
                  important geometric correlations among the
                  high-dimensional decision boundary of classifiers.
                  It further outlines potential security breaches with
                  the existence of single directions in the input
                  space that adversaries can possibly exploit to break
                  a classifier on most natural images.},
  archiveprefix = {arXiv},
  eprint = {1610.08401},
  primaryclass = {cs.CV}
}
</pre>

<a name="kingma-2013-auto-encod"></a><pre>
@article{<a href="index.html#kingma-2013-auto-encod">kingma-2013-auto-encod</a>,
  author = {Kingma, Diederik P and Welling, Max},
  title = {Auto-Encoding Variational Bayes},
  journal = {CoRR},
  year = 2013,
  url = {<a href="http://arxiv.org/abs/1312.6114v10">http://arxiv.org/abs/1312.6114v10</a>},
  abstract = {How can we perform efficient inference and learning
                  in directed probabilistic models, in the presence of
                  continuous latent variables with intractable
                  posterior distributions, and large datasets? We
                  introduce a stochastic variational inference and
                  learning algorithm that scales to large datasets
                  and, under some mild differentiability conditions,
                  even works in the intractable case. Our
                  contributions is two-fold. First, we show that a
                  reparameterization of the variational lower bound
                  yields a lower bound estimator that can be
                  straightforwardly optimized using standard
                  stochastic gradient methods. Second, we show that
                  for i.i.d. datasets with continuous latent variables
                  per datapoint, posterior inference can be made
                  especially efficient by fitting an approximate
                  inference model (also called a recognition model) to
                  the intractable posterior using the proposed lower
                  bound estimator. Theoretical advantages are
                  reflected in experimental results.},
  archiveprefix = {arXiv},
  eprint = {1312.6114},
  primaryclass = {stat.ML}
}
</pre>

<a name="wu-2016-googl-neural"></a><pre>
@article{<a href="index.html#wu-2016-googl-neural">wu-2016-googl-neural</a>,
  author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and
                  Le, Quoc V. and Norouzi, Mohammad and Macherey,
                  Wolfgang and Krikun, Maxim and Cao, Yuan and Gao,
                  Qin and Macherey, Klaus and Klingner, Jeff and Shah,
                  Apurva and Johnson, Melvin and Liu, Xiaobing and
                  Kaiser, Łukasz and Gouws, Stephan and Kato,
                  Yoshikiyo and Kudo, Taku and Kazawa, Hideto and
                  Stevens, Keith and Kurian, George and Patil, Nishant
                  and Wang, Wei and Young, Cliff and Smith, Jason and
                  Riesa, Jason and Rudnick, Alex and Vinyals, Oriol
                  and Corrado, Greg and Hughes, Macduff and Dean,
                  Jeffrey},
  title = {Google's Neural Machine Translation System: Bridging
                  the Gap Between Human and Machine Translation},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1609.08144v2">http://arxiv.org/abs/1609.08144v2</a>},
  abstract = {Neural Machine Translation (NMT) is an end-to-end
                  learning approach for automated translation, with
                  the potential to overcome many of the weaknesses of
                  conventional phrase-based translation systems.
                  Unfortunately, NMT systems are known to be
                  computationally expensive both in training and in
                  translation inference. Also, most NMT systems have
                  difficulty with rare words. These issues have
                  hindered NMT's use in practical deployments and
                  services, where both accuracy and speed are
                  essential. In this work, we present GNMT, Google's
                  Neural Machine Translation system, which attempts to
                  address many of these issues. Our model consists of
                  a deep LSTM network with 8 encoder and 8 decoder
                  layers using attention and residual connections. To
                  improve parallelism and therefore decrease training
                  time, our attention mechanism connects the bottom
                  layer of the decoder to the top layer of the
                  encoder. To accelerate the final translation speed,
                  we employ low-precision arithmetic during inference
                  computations. To improve handling of rare words, we
                  divide words into a limited set of common sub-word
                  units ("wordpieces") for both input and output. This
                  method provides a good balance between the
                  flexibility of "character"-delimited models and the
                  efficiency of "word"-delimited models, naturally
                  handles translation of rare words, and ultimately
                  improves the overall accuracy of the system. Our
                  beam search technique employs a length-normalization
                  procedure and uses a coverage penalty, which
                  encourages generation of an output sentence that is
                  most likely to cover all the words in the source
                  sentence. On the WMT'14 English-to-French and
                  English-to-German benchmarks, GNMT achieves
                  competitive results to state-of-the-art. Using a
                  human side-by-side evaluation on a set of isolated
                  simple sentences, it reduces translation errors by
                  an average of 60 \% compared to Google's
                  phrase-based production system.},
  archiveprefix = {arXiv},
  eprint = {1609.08144},
  primaryclass = {cs.CL}
}
</pre>

<a name="vaswani-2017-atten-is"></a><pre>
@article{<a href="index.html#vaswani-2017-atten-is">vaswani-2017-atten-is</a>,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki
                  and Uszkoreit, Jakob and Jones, Llion and Gomez,
                  Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  title = {Attention Is All You Need},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1706.03762v4">http://arxiv.org/abs/1706.03762v4</a>},
  abstract = {The dominant sequence transduction models are based
                  on complex recurrent or convolutional neural
                  networks in an encoder-decoder configuration. The
                  best performing models also connect the encoder and
                  decoder through an attention mechanism. We propose a
                  new simple network architecture, the Transformer,
                  based solely on attention mechanisms, dispensing
                  with recurrence and convolutions entirely.
                  Experiments on two machine translation tasks show
                  these models to be superior in quality while being
                  more parallelizable and requiring significantly less
                  time to train. Our model achieves 28.4 BLEU on the
                  WMT 2014 English-to-German translation task,
                  improving over the existing best results, including
                  ensembles by over 2 BLEU. On the WMT 2014
                  English-to-French translation task, our model
                  establishes a new single-model state-of-the-art BLEU
                  score of 41.0 after training for 3.5 days on eight
                  GPUs, a small fraction of the training costs of the
                  best models from the literature. We show that the
                  Transformer generalizes well to other tasks by
                  applying it successfully to English constituency
                  parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  eprint = {1706.03762},
  primaryclass = {cs.CL}
}
</pre>

<a name="kaiser-2017-one-model"></a><pre>
@article{<a href="index.html#kaiser-2017-one-model">kaiser-2017-one-model</a>,
  author = {Kaiser, Lukasz and Gomez, Aidan N. and Shazeer, Noam
                  and Vaswani, Ashish and Parmar, Niki and Jones,
                  Llion and Uszkoreit, Jakob},
  title = {One Model To Learn Them All},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1706.05137v1">http://arxiv.org/abs/1706.05137v1</a>},
  abstract = {Deep learning yields great results across many
                  fields, from speech recognition, image
                  classification, to translation. But for each
                  problem, getting a deep model to work well involves
                  research into the architecture and a long period of
                  tuning. We present a single model that yields good
                  results on a number of problems spanning multiple
                  domains. In particular, this single model is trained
                  concurrently on ImageNet, multiple translation
                  tasks, image captioning (COCO dataset), a speech
                  recognition corpus, and an English parsing task. Our
                  model architecture incorporates building blocks from
                  multiple domains. It contains convolutional layers,
                  an attention mechanism, and sparsely-gated layers.
                  Each of these computational blocks is crucial for a
                  subset of the tasks we train on. Interestingly, even
                  if a block is not crucial for a task, we observe
                  that adding it never hurts performance and in most
                  cases improves it on all tasks. We also show that
                  tasks with less data benefit largely from joint
                  training with other tasks, while performance on
                  large tasks degrades only slightly if at all.},
  archiveprefix = {arXiv},
  eprint = {1706.05137},
  primaryclass = {cs.LG}
}
</pre>

<a name="wu-2017-scalab-trust"></a><pre>
@article{<a href="index.html#wu-2017-scalab-trust">wu-2017-scalab-trust</a>,
  author = {Wu, Yuhuai and Mansimov, Elman and Liao, Shun and
                  Grosse, Roger and Ba, Jimmy},
  title = {Scalable Trust-Region Method for Deep Reinforcement
                  Learning Using Kronecker-Factored Approximation},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1708.05144v2">http://arxiv.org/abs/1708.05144v2</a>},
  abstract = {In this work, we propose to apply trust region
                  optimization to deep reinforcement learning using a
                  recently proposed Kronecker-factored approximation
                  to the curvature. We extend the framework of natural
                  policy gradient and propose to optimize both the
                  actor and the critic using Kronecker-factored
                  approximate curvature (K-FAC) with trust region;
                  hence we call our method Actor Critic using
                  Kronecker-Factored Trust Region (ACKTR). To the best
                  of our knowledge, this is the first scalable trust
                  region natural gradient method for actor-critic
                  methods. It is also a method that learns non-trivial
                  tasks in continuous control as well as discrete
                  control policies directly from raw pixel inputs. We
                  tested our approach across discrete domains in Atari
                  games as well as continuous domains in the MuJoCo
                  environment. With the proposed methods, we are able
                  to achieve higher rewards and a 2- to 3-fold
                  improvement in sample efficiency on average,
                  compared to previous state-of-the-art on-policy
                  actor-critic methods. Code is available at
                  https://github.com/openai/baselines},
  archiveprefix = {arXiv},
  eprint = {1708.05144},
  primaryclass = {cs.LG}
}
</pre>

<a name="wen-2016-networ-based"></a><pre>
@article{<a href="index.html#wen-2016-networ-based">wen-2016-networ-based</a>,
  author = {Wen, Tsung-Hsien and Vandyke, David and Mrksic,
                  Nikola and Gasic, Milica and Rojas-Barahona, Lina M.
                  and Su, Pei-Hao and Ultes, Stefan and Young, Steve},
  title = {A Network-Based End-To-End Trainable Task-Oriented
                  Dialogue System},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1604.04562v3">http://arxiv.org/abs/1604.04562v3</a>},
  abstract = {Teaching machines to accomplish tasks by conversing
                  naturally with humans is challenging. Currently,
                  developing task-oriented dialogue systems requires
                  creating multiple components and typically this
                  involves either a large amount of handcrafting, or
                  acquiring costly labelled datasets to solve a
                  statistical learning problem for each component. In
                  this work we introduce a neural network-based
                  text-in, text-out end-to-end trainable goal-oriented
                  dialogue system along with a new way of collecting
                  dialogue data based on a novel pipe-lined
                  Wizard-of-Oz framework. This approach allows us to
                  develop dialogue systems easily and without making
                  too many assumptions about the task at hand. The
                  results show that the model can converse with human
                  subjects naturally whilst helping them to accomplish
                  tasks in a restaurant search domain.},
  archiveprefix = {arXiv},
  eprint = {1604.04562},
  primaryclass = {cs.CL}
}
</pre>

<a name="singh-2017-replac-or"></a><pre>
@article{<a href="index.html#singh-2017-replac-or">singh-2017-replac-or</a>,
  author = {Singh, Vikash},
  title = {Replace Or Retrieve Keywords In Documents At Scale},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.00046v2">http://arxiv.org/abs/1711.00046v2</a>},
  abstract = {In this paper we introduce, the FlashText algorithm
                  for replacing keywords or finding keywords in a
                  given text. FlashText can search or replace keywords
                  in one pass over a document. The time complexity of
                  this algorithm is not dependent on the number of
                  terms being searched or replaced. For a document of
                  size N (characters) and a dictionary of M keywords,
                  the time complexity will be O(N). This algorithm is
                  much faster than Regex, because regex time
                  complexity is O(MxN). It is also different from Aho
                  Corasick Algorithm, as it doesn't match substrings.
                  FlashText is designed to only match complete words
                  (words with boundary characters on both sides). For
                  an input dictionary of {Apple}, this algorithm won't
                  match it to 'I like Pineapple'. This algorithm is
                  also designed to go for the longest match first. For
                  an input dictionary {Machine, Learning, Machine
                  learning} on a string 'I like Machine learning', it
                  will only consider the longest match, which is
                  Machine Learning. We have made python implementation
                  of this algorithm available as open-source on
                  GitHub, released under the permissive MIT License.},
  archiveprefix = {arXiv},
  eprint = {1711.00046},
  primaryclass = {cs.DS}
}
</pre>

<a name="kleppmann-2016-confl-free"></a><pre>
@article{<a href="index.html#kleppmann-2016-confl-free">kleppmann-2016-confl-free</a>,
  author = {Kleppmann, Martin and Beresford, Alastair R.},
  title = {A Conflict-Free Replicated Json Datatype},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1608.03960v3">http://arxiv.org/abs/1608.03960v3</a>},
  abstract = {Many applications model their data in a
                  general-purpose storage format such as JSON. This
                  data structure is modified by the application as a
                  result of user input. Such modifications are well
                  understood if performed sequentially on a single
                  copy of the data, but if the data is replicated and
                  modified concurrently on multiple devices, it is
                  unclear what the semantics should be. In this paper
                  we present an algorithm and formal semantics for a
                  JSON data structure that automatically resolves
                  concurrent modifications such that no updates are
                  lost, and such that all replicas converge towards
                  the same state (a conflict-free replicated datatype
                  or CRDT). It supports arbitrarily nested list and
                  map types, which can be modified by insertion,
                  deletion and assignment. The algorithm performs all
                  merging client-side and does not depend on ordering
                  guarantees from the network, making it suitable for
                  deployment on mobile devices with poor network
                  connectivity, in peer-to-peer networks, and in
                  messaging systems with end-to-end encryption.},
  archiveprefix = {arXiv},
  eprint = {1608.03960},
  primaryclass = {cs.DC}
}
</pre>

<a name="lample-2017-unsup-machin"></a><pre>
@article{<a href="index.html#lample-2017-unsup-machin">lample-2017-unsup-machin</a>,
  author = {Lample, Guillaume and Denoyer, Ludovic and Ranzato,
                  Marc'Aurelio},
  title = {Unsupervised Machine Translation Using Monolingual
                  Corpora Only},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.00043v1">http://arxiv.org/abs/1711.00043v1</a>},
  abstract = {Machine translation has recently achieved impressive
                  performance thanks to recent advances in deep
                  learning and the availability of large-scale
                  parallel corpora. There have been numerous attempts
                  to extend these successes to low-resource language
                  pairs, yet requiring tens of thousands of parallel
                  sentences. In this work, we take this research
                  direction to the extreme and investigate whether it
                  is possible to learn to translate even without any
                  parallel data. We propose a model that takes
                  sentences from monolingual corpora in two different
                  languages and maps them into the same latent space.
                  By learning to reconstruct in both languages from
                  this shared feature space, the model effectively
                  learns to translate without using any labeled data.
                  We demonstrate our model on two widely used datasets
                  and two language pairs, reporting BLEU scores up to
                  32.8, without using even a single parallel sentence
                  at training time.},
  archiveprefix = {arXiv},
  eprint = {1711.00043},
  primaryclass = {cs.CL}
}
</pre>

<a name="chaudhuri-2017-fast-precis"></a><pre>
@article{<a href="index.html#chaudhuri-2017-fast-precis">chaudhuri-2017-fast-precis</a>,
  author = {Chaudhuri, Avik and Vekris, Panagiotis and Goldman,
                  Sam and Roch, Marshall and Levi, Gabriel},
  title = {Fast and Precise Type Checking for Javascript},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1708.08021v2">http://arxiv.org/abs/1708.08021v2</a>},
  abstract = {In this paper we present the design and
                  implementation of Flow, a fast and precise type
                  checker for JavaScript that is used by thousands of
                  developers on millions of lines of code at Facebook
                  every day. Flow uses sophisticated type inference to
                  understand common JavaScript idioms precisely. This
                  helps it find non-trivial bugs in code and provide
                  code intelligence to editors without requiring
                  significant rewriting or annotations from the
                  developer. We formalize an important fragment of
                  Flow's analysis and prove its soundness.
                  Furthermore, Flow uses aggressive parallelization
                  and incrementalization to deliver near-instantaneous
                  response times. This helps it avoid introducing any
                  latency in the usual edit-refresh cycle of rapid
                  JavaScript development. We describe the algorithms
                  and systems infrastructure that we built to scale
                  Flow's analysis.},
  archiveprefix = {arXiv},
  eprint = {1708.08021},
  primaryclass = {cs.PL}
}
</pre>

<a name="tolstikhin-2017-wasser-auto-encod"></a><pre>
@article{<a href="index.html#tolstikhin-2017-wasser-auto-encod">tolstikhin-2017-wasser-auto-encod</a>,
  author = {Tolstikhin, Ilya and Bousquet, Olivier and Gelly,
                  Sylvain and Schoelkopf, Bernhard},
  title = {Wasserstein Auto-Encoders},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.01558v1">http://arxiv.org/abs/1711.01558v1</a>},
  abstract = {We propose the Wasserstein Auto-Encoder (WAE)---a
                  new algorithm for building a generative model of the
                  data distribution. WAE minimizes a penalized form of
                  the Wasserstein distance between the model
                  distribution and the target distribution, which
                  leads to a different regularizer than the one used
                  by the Variational Auto-Encoder (VAE). This
                  regularizer encourages the encoded training
                  distribution to match the prior. We compare our
                  algorithm with several other techniques and show
                  that it is a generalization of adversarial
                  auto-encoders (AAE). Our experiments show that WAE
                  shares many of the properties of VAEs (stable
                  training, encoder-decoder architecture, nice latent
                  manifold structure) while generating samples of
                  better quality, as measured by the FID score.},
  archiveprefix = {arXiv},
  eprint = {1711.01558v1},
  primaryclass = {stat.ML}
}
</pre>

<a name="he-2017-wider-deeper"></a><pre>
@article{<a href="index.html#he-2017-wider-deeper">he-2017-wider-deeper</a>,
  author = {He, Zhen and Gao, Shaobing and Xiao, Liang and Liu,
                  Daxue and He, Hangen and Barber, David},
  title = {Wider and Deeper, Cheaper and Faster: Tensorized
                  Lstms for Sequence Learning},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.01577v2">http://arxiv.org/abs/1711.01577v2</a>},
  abstract = {Long Short-Term Memory (LSTM) is a popular approach
                  to boosting the ability of Recurrent Neural Networks
                  to store longer term temporal information. The
                  capacity of an LSTM network can be increased by
                  widening and adding layers. However, usually the
                  former introduces additional parameters, while the
                  latter increases the runtime. As an alternative we
                  propose the Tensorized LSTM in which the hidden
                  states are represented by tensors and updated via a
                  cross-layer convolution. By increasing the tensor
                  size, the network can be widened efficiently without
                  additional parameters since the parameters are
                  shared across different locations in the tensor; by
                  delaying the output, the network can be deepened
                  implicitly with little additional runtime since deep
                  computations for each timestep are merged into
                  temporal computations of the sequence. Experiments
                  conducted on five challenging sequence learning
                  tasks show the potential of the proposed model.},
  archiveprefix = {arXiv},
  eprint = {1711.01577v2},
  primaryclass = {stat.ML}
}
</pre>

<a name="sriram-2017-robus-speec"></a><pre>
@article{<a href="index.html#sriram-2017-robus-speec">sriram-2017-robus-speec</a>,
  author = {Sriram, Anuroop and Jun, Heewoo and Gaur, Yashesh
                  and Satheesh, Sanjeev},
  title = {Robust Speech Recognition Using Generative
                  Adversarial Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.01567v1">http://arxiv.org/abs/1711.01567v1</a>},
  abstract = {This paper describes a general, scalable, end-to-end
                  framework that uses the generative adversarial
                  network (GAN) objective to enable robust speech
                  recognition. Encoders trained with the proposed
                  approach enjoy improved invariance by learning to
                  map noisy audio to the same embedding space as that
                  of clean audio. Unlike previous methods, the new
                  framework does not rely on domain expertise or
                  simplifying assumptions as are often needed in
                  signal processing, and directly encourages
                  robustness in a data-driven way. We show the new
                  approach improves simulated far-field speech
                  recognition of vanilla sequence-to-sequence models
                  without specialized front-ends or preprocessing.},
  archiveprefix = {arXiv},
  eprint = {1711.01567v1},
  primaryclass = {cs.CL}
}
</pre>

<a name="kang-2017-visual-aware"></a><pre>
@article{<a href="index.html#kang-2017-visual-aware">kang-2017-visual-aware</a>,
  author = {Kang, Wang-Cheng and Fang, Chen and Wang, Zhaowen
                  and McAuley, Julian},
  title = {Visually-Aware Fashion Recommendation and Design
                  With Generative Image Models},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02231v1">http://arxiv.org/abs/1711.02231v1</a>},
  abstract = {Building effective recommender systems for domains
                  like fashion is challenging due to the high level of
                  subjectivity and the semantic complexity of the
                  features involved (i.e., fashion styles). Recent
                  work has shown that approaches to `visual'
                  recommendation (e.g.~clothing, art, etc.) can be
                  made more accurate by incorporating visual signals
                  directly into the recommendation objective, using
                  `off-the-shelf' feature representations derived from
                  deep networks. Here, we seek to extend this
                  contribution by showing that recommendation
                  performance can be significantly improved by
                  learning `fashion aware' image representations
                  directly, i.e., by training the image representation
                  (from the pixel level) and the recommender system
                  jointly; this contribution is related to recent work
                  using Siamese CNNs, though we are able to show
                  improvements over state-of-the-art recommendation
                  techniques such as BPR and variants that make use of
                  pre-trained visual features. Furthermore, we show
                  that our model can be used \emph{generatively},
                  i.e., given a user and a product category, we can
                  generate new images (i.e., clothing items) that are
                  most consistent with their personal taste. This
                  represents a first step towards building systems
                  that go beyond recommending existing items from a
                  product corpus, but which can be used to suggest
                  styles and aid the design of new products.},
  archiveprefix = {arXiv},
  eprint = {1711.02231v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="choi-2017-can-maxout"></a><pre>
@article{<a href="index.html#choi-2017-can-maxout">choi-2017-can-maxout</a>,
  author = {Choi, Jae-Seok and Kim, Munchurl},
  title = {Can Maxout Units Downsize Restoration Networks? -
                  Single Image Super-Resolution Using Lightweight Cnn
                  With Maxout Units},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02321v1">http://arxiv.org/abs/1711.02321v1</a>},
  abstract = {Rectified linear units (ReLU) are well-known to be
                  helpful in obtaining faster convergence and thus
                  higher performance for many deep-learning-based
                  applications. However, networks with ReLU tend to
                  perform poorly when the number of filter parameters
                  is constrained to a small number. To overcome it, in
                  this paper, we propose a novel network utilizing
                  maxout units (MU), and show its effectiveness on
                  super-resolution (SR) applications. In general, the
                  MU has been known to make the filter sizes doubled
                  in generating the feature maps of the same sizes in
                  classification problems. In this paper, we first
                  reveal that the MU can even make the filter sizes
                  halved in restoration problems thus leading to
                  compaction of the network sizes. To show this, our
                  SR network is designed without increasing the filter
                  sizes with MU, which outperforms the state of the
                  art SR methods with a smaller number of filter
                  parameters. To the best of our knowledge, we are the
                  first to incorporate MU into SR applications and
                  show promising performance results. In MU, feature
                  maps from a previous convolutional layer are divided
                  into two parts along channels, which are then
                  compared element-wise and only their max values are
                  passed to a next layer. Along with some interesting
                  properties of MU to be analyzed, we further
                  investigate other variants of MU and their effects.
                  In addition, while ReLU have a trouble for learning
                  in networks with a very small number of
                  convolutional filter parameters, MU do not. For SR
                  applications, our MU-based network reconstructs
                  high-resolution images with comparable quality
                  compared to previous deep-learning-based SR methods,
                  with lower filter parameters.},
  archiveprefix = {arXiv},
  eprint = {1711.02321v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="trattner-2017-food-recom-system"></a><pre>
@article{<a href="index.html#trattner-2017-food-recom-system">trattner-2017-food-recom-system</a>,
  author = {Trattner, Christoph and Elsweiler, David},
  title = {Food Recommender Systems: Important Contributions,
                  Challenges and Future Research Directions},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02760v2">http://arxiv.org/abs/1711.02760v2</a>},
  abstract = {The recommendation of food items is important for
                  many reasons. Attaining cooking inspiration via
                  digital sources is becoming evermore popular; as are
                  systems, which recommend other types of food, such
                  as meals in restaurants or products in supermarkets.
                  Researchers have been studying these kinds of
                  systems for many years, suggesting not only that can
                  they be a means to help people find food they might
                  want to eat, but also help them nourish themselves
                  more healthily. This paper provides a summary of the
                  state-of-the-art of so-called food recommender
                  systems, highlighting both seminal and most recent
                  approaches to the problem, as well as important
                  specializations, such as food recommendation systems
                  for groups of users or systems which promote healthy
                  eating. We moreover discuss the diverse challenges
                  involved in designing recsys for food, summarise the
                  lessons learned from past research and outline what
                  we believe to be important future directions and
                  open questions for the field. In providing these
                  contributions we hope to provide a useful resource
                  for researchers and practitioners alike.},
  archiveprefix = {arXiv},
  eprint = {1711.02760},
  primaryclass = {cs.IR}
}
</pre>

<a name="melis-2017-state-art"></a><pre>
@article{<a href="index.html#melis-2017-state-art">melis-2017-state-art</a>,
  author = {Melis, G{\'a}bor and Dyer, Chris and Blunsom, Phil},
  title = {On the State of the Art of Evaluation in Neural
                  Language Models},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1707.05589v1">http://arxiv.org/abs/1707.05589v1</a>},
  abstract = {Ongoing innovations in recurrent neural network
                  architectures have provided a steady influx of
                  apparently state-of-the-art results on language
                  modelling benchmarks. However, these have been
                  evaluated using differing code bases and limited
                  computational resources, which represent
                  uncontrolled sources of experimental variation. We
                  reevaluate several popular architectures and
                  regularisation methods with large-scale automatic
                  black-box hyperparameter tuning and arrive at the
                  somewhat surprising conclusion that standard LSTM
                  architectures, when properly regularised, outperform
                  more recent models. We establish a new state of the
                  art on the Penn Treebank and Wikitext-2 corpora, as
                  well as strong baselines on the Hutter Prize
                  dataset.},
  archiveprefix = {arXiv},
  eprint = {1707.05589},
  primaryclass = {cs.CL}
}
</pre>

<a name="rahman-2017-contin-integ"></a><pre>
@article{<a href="index.html#rahman-2017-contin-integ">rahman-2017-contin-integ</a>,
  author = {Rahman, Akond and Agrawal, Amritanshu and Krishna,
                  Rahul and Sobran, Alexander and Menzies, Tim},
  title = {Continuous Integration: The Silver Bullet?},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.03933v1">http://arxiv.org/abs/1711.03933v1</a>},
  abstract = {Continuous integration (CI) tools integrate code
                  changes by automatically compiling, building, and
                  executing test cases upon submission of code
                  changes. Use of CI tools is getting increasingly
                  popular, yet how proprietary projects reap the
                  benefits of CI remains unknown. To investigate the
                  influence of CI on software development, we mine 661
                  open source software (OSS) projects, and 171
                  proprietary projects. For OSS projects, we observe
                  the expected benefits after CI adoption, i.e. more
                  bugs are resolved, and more issues are resolved.
                  However, for the proprietary projects, we cannot
                  make similar observations. Therefore, we cannot
                  claim that CI is the `silver bullet' for software
                  development. Why is this so? Our findings indicate
                  that only adoption of CI might not be enough to
                  improve software development. CI can be effective
                  for software development if practitioners use CI's
                  feedback mechanism efficiently, by applying the
                  practice of making frequent commits. For proprietary
                  projects we observe practitioners to commit less
                  frequently, and hence not use CI effectively, for
                  obtaining feedback on the submitted code changes. We
                  recommend practitioners to (i) apply the CI best
                  practices along with adoption of CI tools, (ii)
                  consider their team's development context before
                  adopting CI tools, and (iii) after adoption of CI,
                  investigate if CI satisfies their needs by applying
                  software analytics.},
  archiveprefix = {arXiv},
  eprint = {1711.03933},
  primaryclass = {cs.SE}
}
</pre>

<a name="iandola-2016-squeez"></a><pre>
@article{<a href="index.html#iandola-2016-squeez">iandola-2016-squeez</a>,
  author = {Iandola, Forrest N. and Han, Song and Moskewicz,
                  Matthew W. and Ashraf, Khalid and Dally, William J.
                  and Keutzer, Kurt},
  title = {Squeezenet: Alexnet-Level Accuracy With 50x Fewer
                  Parameters and $<$0.5MB Model Size},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1602.07360v4">http://arxiv.org/abs/1602.07360v4</a>},
  abstract = {Recent research on deep neural networks has focused
                  primarily on improving accuracy. For a given
                  accuracy level, it is typically possible to identify
                  multiple DNN architectures that achieve that
                  accuracy level. With equivalent accuracy, smaller
                  DNN architectures offer at least three advantages:
                  (1) Smaller DNNs require less communication across
                  servers during distributed training. (2) Smaller
                  DNNs require less bandwidth to export a new model
                  from the cloud to an autonomous car. (3) Smaller
                  DNNs are more feasible to deploy on FPGAs and other
                  hardware with limited memory. To provide all of
                  these advantages, we propose a small DNN
                  architecture called SqueezeNet. SqueezeNet achieves
                  AlexNet-level accuracy on ImageNet with 50x fewer
                  parameters. Additionally, with model compression
                  techniques we are able to compress SqueezeNet to
                  less than 0.5MB (510x smaller than AlexNet). The
                  SqueezeNet architecture is available for download
                  here: https://github.com/DeepScale/SqueezeNet},
  archiveprefix = {arXiv},
  eprint = {1602.07360},
  primaryclass = {cs.CV}
}
</pre>

<a name="pons-2017-end-to"></a><pre>
@article{<a href="index.html#pons-2017-end-to">pons-2017-end-to</a>,
  author = {Pons, Jordi and Nieto, Oriol and Prockup, Matthew
                  and Schmidt, Erik M. and Ehmann, Andreas F. and
                  Serra, Xavier},
  title = {End-To-End Learning for Music Audio Tagging At
                  Scale},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02520v2">http://arxiv.org/abs/1711.02520v2</a>},
  abstract = {The lack of data tends to limit the outcomes of deep
                  learning research - specially, when dealing with
                  end-to-end learning stacks processing raw data such
                  as waveforms. In this study we make use of musical
                  labels annotated for 1.2 million tracks. This large
                  amount of data allows us to unrestrictedly explore
                  different front-end paradigms: from assumption-free
                  models - using waveforms as input with very small
                  convolutional filters; to models that rely on domain
                  knowledge - log-mel spectrograms with a
                  convolutional neural network designed to learn
                  temporal and timbral features. Results suggest that
                  while spectrogram-based models surpass their
                  waveform-based counterparts, the difference in
                  performance shrinks as more data are employed.},
  archiveprefix = {arXiv},
  eprint = {1711.02520},
  primaryclass = {cs.SD}
}
</pre>

<a name="seo-2017-neural-speed"></a><pre>
@article{<a href="index.html#seo-2017-neural-speed">seo-2017-neural-speed</a>,
  author = {Seo, Minjoon and Min, Sewon and Farhadi, Ali and
                  Hajishirzi, Hannaneh},
  title = {Neural Speed Reading Via Skim-Rnn},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02085v2">http://arxiv.org/abs/1711.02085v2</a>},
  abstract = {Inspired by the principles of speed reading, we
                  introduce Skim-RNN, a recurrent neural network (RNN)
                  that dynamically decides to update only a small
                  fraction of the hidden state for relatively
                  unimportant input tokens. Skim-RNN gives
                  computational advantage over an RNN that always
                  updates the entire hidden state. Skim-RNN uses the
                  same input and output interfaces as a standard RNN
                  and can be easily used instead of RNNs in existing
                  models. In our experiments, we show that Skim-RNN
                  can achieve significantly reduced computational cost
                  without losing accuracy compared to standard RNNs
                  across five different natural language tasks. In
                  addition, we demonstrate that the trade-off between
                  accuracy and speed of Skim-RNN can be dynamically
                  controlled during inference time in a stable manner.
                  Our analysis also shows that Skim-RNN running on a
                  single CPU offers lower latency compared to standard
                  RNNs on GPUs.},
  archiveprefix = {arXiv},
  eprint = {1711.02085},
  primaryclass = {cs.CL}
}
</pre>

<a name="wang-2017-iterat-school"></a><pre>
@article{<a href="index.html#wang-2017-iterat-school">wang-2017-iterat-school</a>,
  author = {Wang, Zhongxiang and Shafahi, Ali and Haghani, Ali},
  title = {An Iterative School Decomposition Algorithm for
                  Solving the Multi-School Bus Routing and Scheduling
                  Problem},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.00532v2">http://arxiv.org/abs/1711.00532v2</a>},
  abstract = {Servicing the school transportation demand safely
                  with a minimum number of buses is one of the highest
                  financial goals for school transportation directors.
                  To achieve that objective, a good and efficient way
                  to solve the routing and scheduling problem is
                  required. Due to the growth of the computing power,
                  the spotlight has been shed on solving the combined
                  problem of the school bus routing and scheduling. A
                  recent attempt tried to model the routing problem by
                  maximizing the trip compatibilities with the hope of
                  requiring fewer buses in the scheduling problem.
                  However, an over-counting problem associated with
                  trip compatibility could diminish the performance of
                  this approach. An extended model is proposed in this
                  paper to resolve this issue along with an iterative
                  solution algorithm. This extended model is an
                  integrated model for multi-school bus routing and
                  scheduling problem. The result shows better
                  solutions for 8 test problems can be found with a
                  fewer number of buses (up to 25 \%) and shorter
                  travel time (up to 7 \% per trip).},
  archiveprefix = {arXiv},
  eprint = {1711.00532},
  primaryclass = {math.OC}
}
</pre>

<a name="young-2017-augmen-end"></a><pre>
@article{<a href="index.html#young-2017-augmen-end">young-2017-augmen-end</a>,
  author = {Young, Tom and Cambria, Erik and Chaturvedi, Iti and
                  Huang, Minlie and Zhou, Hao and Biswas, Subham},
  title = {Augmenting End-To-End Dialog Systems With
                  Commonsense Knowledge},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1709.05453v2">http://arxiv.org/abs/1709.05453v2</a>},
  abstract = {Building dialog agents that can converse naturally
                  with humans is a challenging yet intriguing problem
                  of artificial intelligence. In open-domain
                  human-computer conversation, where the
                  conversational agent is expected to respond to human
                  responses in an interesting and engaging way,
                  commonsense knowledge has to be integrated into the
                  model effectively. In this paper, we investigate the
                  impact of providing commonsense knowledge about the
                  concepts covered in the dialog. Our model represents
                  the first attempt to integrating a large commonsense
                  knowledge base into end-to-end conversational
                  models. In the retrieval-based scenario, we propose
                  the Tri-LSTM model to jointly take into account
                  message and commonsense for selecting an appropriate
                  response. Our experiments suggest that the
                  knowledge-augmented models are superior to their
                  knowledge-free counterparts in automatic
                  evaluation.},
  archiveprefix = {arXiv},
  eprint = {1709.05453},
  primaryclass = {cs.AI}
}
</pre>

<a name="nanfack-2017-squeez-segnet"></a><pre>
@article{<a href="index.html#nanfack-2017-squeez-segnet">nanfack-2017-squeez-segnet</a>,
  author = {Nanfack, Geraldin and Elhassouny, Azeddine and
                  Thami, Rachid Oulad Haj},
  title = {Squeeze-Segnet: A New Fast Deep Convolutional Neural
                  Network for Semantic Segmentation},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.05491v1">http://arxiv.org/abs/1711.05491v1</a>},
  abstract = {The recent researches in Deep Convolutional Neural
                  Network have focused their attention on improving
                  accuracy that provide significant advances. However,
                  if they were limited to classification tasks,
                  nowadays with contributions from Scientific
                  Communities who are embarking in this field, they
                  have become very useful in higher level tasks such
                  as object detection and pixel-wise semantic
                  segmentation. Thus, brilliant ideas in the field of
                  semantic segmentation with deep learning have
                  completed the state of the art of accuracy, however
                  this architectures become very difficult to apply in
                  embedded systems as is the case for autonomous
                  driving. We present a new Deep fully Convolutional
                  Neural Network for pixel-wise semantic segmentation
                  which we call Squeeze-SegNet. The architecture is
                  based on Encoder-Decoder style. We use a
                  SqueezeNet-like encoder and a decoder formed by our
                  proposed squeeze-decoder module and upsample layer
                  using downsample indices like in SegNet and we add a
                  deconvolution layer to provide final multi-channel
                  feature map. On datasets like Camvid or City-states,
                  our net gets SegNet-level accuracy with less than 10
                  times fewer parameters than SegNet.},
  archiveprefix = {arXiv},
  eprint = {1711.05491},
  primaryclass = {cs.CV}
}
</pre>

<a name="ringgaard-2017-sling"></a><pre>
@article{<a href="index.html#ringgaard-2017-sling">ringgaard-2017-sling</a>,
  author = {Ringgaard, Michael and Gupta, Rahul and Pereira,
                  Fernando C. N.},
  title = {Sling: A Framework for Frame Semantic Parsing},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.07032v1">http://arxiv.org/abs/1710.07032v1</a>},
  abstract = {We describe SLING, a framework for parsing natural
                  language into semantic frames. SLING supports
                  general transition-based, neural-network parsing
                  with bidirectional LSTM input encoding and a
                  Transition Based Recurrent Unit (TBRU) for output
                  decoding. The parsing model is trained end-to-end
                  using only the text tokens as input. The transition
                  system has been designed to output frame graphs
                  directly without any intervening symbolic
                  representation. The SLING framework includes an
                  efficient and scalable frame store implementation as
                  well as a neural network JIT compiler for fast
                  inference during parsing. SLING is implemented in
                  C++ and it is available for download on GitHub.},
  archiveprefix = {arXiv},
  eprint = {1710.07032},
  primaryclass = {cs.CL}
}
</pre>

<a name="creswell-2017-gener-adver-networ"></a><pre>
@article{<a href="index.html#creswell-2017-gener-adver-networ">creswell-2017-gener-adver-networ</a>,
  author = {Creswell, Antonia and White, Tom and Dumoulin,
                  Vincent and Arulkumaran, Kai and Sengupta, Biswa and
                  Bharath, Anil A},
  title = {Generative Adversarial Networks: An Overview},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.07035v1">http://arxiv.org/abs/1710.07035v1</a>},
  abstract = {Generative adversarial networks (GANs) provide a way
                  to learn deep representations without extensively
                  annotated training data. They achieve this through
                  deriving backpropagation signals through a
                  competitive process involving a pair of networks.
                  The representations that can be learned by GANs may
                  be used in a variety of applications, including
                  image synthesis, semantic image editing, style
                  transfer, image super-resolution and classification.
                  The aim of this review paper is to provide an
                  overview of GANs for the signal processing
                  community, drawing on familiar analogies and
                  concepts where possible. In addition to identifying
                  different methods for training and constructing
                  GANs, we also point to remaining challenges in their
                  theory and application.},
  archiveprefix = {arXiv},
  eprint = {1710.07035},
  primaryclass = {cs.CV}
}
</pre>

<a name="antoniou-2017-data-augmen"></a><pre>
@article{<a href="index.html#antoniou-2017-data-augmen">antoniou-2017-data-augmen</a>,
  author = {Antoniou, Antreas and Storkey, Amos and Edwards,
                  Harrison},
  title = {Data Augmentation Generative Adversarial Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.04340v1">http://arxiv.org/abs/1711.04340v1</a>},
  abstract = {Effective training of neural networks requires much
                  data. In the low-data regime, parameters are
                  underdetermined, and learnt networks generalise
                  poorly. Data Augmentation
                  \cite{krizhevsky2012imagenet} alleviates this by
                  using existing data more effectively. However
                  standard data augmentation produces only limited
                  plausible alternative data. Given there is potential
                  to generate a much broader set of augmentations, we
                  design and train a generative model to do data
                  augmentation. The model, based on image conditional
                  Generative Adversarial Networks, takes data from a
                  source domain and learns to take any data item and
                  generalise it to generate other within-class data
                  items. As this generative process does not depend on
                  the classes themselves, it can be applied to novel
                  unseen classes of data. We show that a Data
                  Augmentation Generative Adversarial Network (DAGAN)
                  augments standard vanilla classifiers well. We also
                  show a DAGAN can enhance few-shot learning systems
                  such as Matching Networks. We demonstrate these
                  approaches on Omniglot, on EMNIST having learnt the
                  DAGAN on Omniglot, and VGG-Face data. In our
                  experiments we can see over 13\ \% increase in
                  accuracy in the low-data regime experiments in
                  Omniglot (from 69\ \% to 82\ \%), EMNIST (73.9\ \%
                  to 76\ \%) and VGG-Face (4.5\ \% to 12\ \%); in
                  Matching Networks for Omniglot we observe an
                  increase of 0.5\ \% (from 96.9\ \% to 97.4\ \%) and
                  an increase of 1.8\ \% in EMNIST (from 59.5\ \% to
                  61.3\ \%).},
  archiveprefix = {arXiv},
  eprint = {1711.04340v1},
  primaryclass = {stat.ML}
}
</pre>

<a name="zhang-2017-advan-variat-infer"></a><pre>
@article{<a href="index.html#zhang-2017-advan-variat-infer">zhang-2017-advan-variat-infer</a>,
  author = {Zhang, Cheng and Butepage, Judith and Kjellstrom,
                  Hedvig and Mandt, Stephan},
  title = {Advances in Variational Inference},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.05597v1">http://arxiv.org/abs/1711.05597v1</a>},
  abstract = {Many modern unsupervised or semi-supervised machine
                  learning algorithms rely on Bayesian probabilistic
                  models. These models are usually intractable and
                  thus require approximate inference. Variational
                  inference (VI) lets us approximate a
                  high-dimensional Bayesian posterior with a simpler
                  variational distribution by solving an optimization
                  problem. This approach has been successfully used in
                  various models and large-scale applications. In this
                  review, we give an overview of recent trends in
                  variational inference. We first introduce standard
                  mean field variational inference, then review recent
                  advances focusing on the following aspects: (a)
                  scalable VI, which includes stochastic
                  approximations, (b) generic VI, which extends the
                  applicability of VI to a large class of otherwise
                  intractable models, such as non-conjugate models,
                  (c) accurate VI, which includes variational models
                  beyond the mean field approximation or with atypical
                  divergences, and (d) amortized VI, which implements
                  the inference over local latent variables with
                  inference networks. Finally, we provide a summary of
                  promising future research directions.},
  archiveprefix = {arXiv},
  eprint = {1711.05597v1},
  primaryclass = {cs.LG}
}
</pre>

<a name="loshchilov-2017-fixin-weigh"></a><pre>
@article{<a href="index.html#loshchilov-2017-fixin-weigh">loshchilov-2017-fixin-weigh</a>,
  author = {Loshchilov, Ilya and Hutter, Frank},
  title = {Fixing Weight Decay Regularization in Adam},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.05101v1">http://arxiv.org/abs/1711.05101v1</a>},
  abstract = {We note that common implementations of adaptive
                  gradient algorithms, such as Adam, limit the
                  potential benefit of weight decay regularization,
                  because the weights do not decay multiplicatively
                  (as would be expected for standard weight decay) but
                  by an additive constant factor. We propose a simple
                  way to resolve this issue by decoupling weight decay
                  and the optimization steps taken w.r.t. the loss
                  function. We provide empirical evidence that our
                  proposed modification (i) decouples the optimal
                  choice of weight decay factor from the setting of
                  the learning rate for both standard SGD and Adam,
                  and (ii) substantially improves Adam's
                  generalization performance, allowing it to compete
                  with SGD with momentum on image classification
                  datasets (on which it was previously typically
                  outperformed by the latter). We also demonstrate
                  that longer optimization runs require smaller weight
                  decay values for optimal results and introduce a
                  normalized variant of weight decay to reduce this
                  dependence. Finally, we propose a version of Adam
                  with warm restarts (AdamWR) that has strong anytime
                  performance while achieving state-of-the-art results
                  on CIFAR-10 and ImageNet32x32. Our source code is
                  available at
                  https://github.com/loshchil/AdamW-and-SGDW},
  archiveprefix = {arXiv},
  eprint = {1711.05101v1},
  primaryclass = {cs.LG}
}
</pre>

<a name="liang-2017-new-method"></a><pre>
@article{<a href="index.html#liang-2017-new-method">liang-2017-new-method</a>,
  author = {Liang, Jiaxi and Chenouri, Shojaeddin and Small,
                  Christopher G.},
  title = {A New Method for Performance Analysis in Nonlinear
                  Dimensionality Reduction},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.06252v1">http://arxiv.org/abs/1711.06252v1</a>},
  abstract = {In this paper, we develop a local rank correlation
                  measure which quantifies the performance of
                  dimension reduction methods. The local rank
                  correlation is easily interpretable, and robust
                  against the extreme skewness of nearest neighbor
                  distributions in high dimensions. Some benchmark
                  datasets are studied. We find that the local rank
                  correlation closely corresponds to our visual
                  interpretation of the quality of the output. In
                  addition, we demonstrate that the local rank
                  correlation is useful in estimating the intrinsic
                  dimensionality of the original data, and in
                  selecting a suitable value of tuning parameters used
                  in some algorithms.},
  archiveprefix = {arXiv},
  eprint = {1711.06252v1},
  primaryclass = {stat.ME}
}
</pre>

<a name="lai-2015-giraf"></a><pre>
@article{<a href="index.html#lai-2015-giraf">lai-2015-giraf</a>,
  author = {Lai, Matthew},
  title = {Giraffe: Using Deep Reinforcement Learning To Play
                  Chess},
  journal = {CoRR},
  year = 2015,
  url = {<a href="http://arxiv.org/abs/1509.01549v2">http://arxiv.org/abs/1509.01549v2</a>},
  abstract = {This report presents Giraffe, a chess engine that
                  uses self-play to discover all its domain-specific
                  knowledge, with minimal hand-crafted knowledge given
                  by the programmer. Unlike previous attempts using
                  machine learning only to perform parameter-tuning on
                  hand-crafted evaluation functions, Giraffe's
                  learning system also performs automatic feature
                  extraction and pattern recognition. The trained
                  evaluation function performs comparably to the
                  evaluation functions of state-of-the-art chess
                  engines - all of which containing thousands of lines
                  of carefully hand-crafted pattern recognizers, tuned
                  over many years by both computer chess experts and
                  human chess masters. Giraffe is the most successful
                  attempt thus far at using end-to-end machine
                  learning to play chess.},
  archiveprefix = {arXiv},
  eprint = {1509.01549},
  primaryclass = {cs.AI}
}
</pre>

<a name="chen-2017-survey-dialog-system"></a><pre>
@article{<a href="index.html#chen-2017-survey-dialog-system">chen-2017-survey-dialog-system</a>,
  author = {Chen, Hongshen and Liu, Xiaorui and Yin, Dawei and
                  Tang, Jiliang},
  title = {A Survey on Dialogue Systems: Recent Advances and
                  New Frontiers},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.01731v2">http://arxiv.org/abs/1711.01731v2</a>},
  abstract = {Dialogue systems have attracted more and more
                  attention. Recent advances on dialogue systems are
                  overwhelmingly contributed by deep learning
                  techniques, which have been employed to enhance a
                  wide range of big data applications such as computer
                  vision, natural language processing, and recommender
                  systems. For dialogue systems, deep learning can
                  leverage a massive amount of data to learn
                  meaningful feature representations and response
                  generation strategies, while requiring a minimum
                  amount of hand-crafting. In this article, we give an
                  overview to these recent advances on dialogue
                  systems from various perspectives and discuss some
                  possible research directions. In particular, we
                  generally divide existing dialogue systems into
                  task-oriented and non-task-oriented models, then
                  detail how deep learning techniques help them with
                  representative algorithms and finally discuss some
                  appealing research directions that can bring the
                  dialogue system research into a new frontier.},
  archiveprefix = {arXiv},
  eprint = {1711.01731},
  primaryclass = {cs.CL}
}
</pre>

<a name="mohapatra-2016-effic-optim"></a><pre>
@article{<a href="index.html#mohapatra-2016-effic-optim">mohapatra-2016-effic-optim</a>,
  author = {Mohapatra, Pritish and Rolinek, Michal and Jawahar,
                  C. V. and Kolmogorov, Vladimir and Kumar, M. Pawan},
  title = {Efficient Optimization for Rank-Based Loss
                  Functions},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1604.08269v2">http://arxiv.org/abs/1604.08269v2</a>},
  abstract = {The accuracy of information retrieval systems is
                  often measured using complex loss functions such as
                  the average precision (AP) or the normalized
                  discounted cumulative gain (NDCG). Given a set of
                  positive (relevant) and negative (non-relevant)
                  samples, the parameters of a retrieval system can be
                  estimated by minimizing these loss functions.
                  However, the non-differentiability and
                  non-decomposability of these loss functions does not
                  allow for simple gradient based optimization
                  algorithms. This issue is generally circumvented by
                  either optimizing a structured hinge-loss upper
                  bound to the loss function or by using asymptotic
                  methods like the direct-loss minimization framework.
                  Yet, the high computational complexity of
                  loss-augmented inference, which is necessary for
                  both the frameworks, prohibits its use in large
                  training data sets. To alleviate this deficiency, we
                  present a novel quicksort flavored algorithm for a
                  large class of non-decomposable loss functions. We
                  provide a complete characterization of the loss
                  functions that are amenable to our algorithm, and
                  show that it includes both AP and NDCG based loss
                  functions. Furthermore, we prove that no comparison
                  based algorithm can improve upon the computational
                  complexity of our approach asymptotically. We
                  demonstrate the effectiveness of our approach in the
                  context of optimizing the structured hinge loss
                  upper bound of AP and NDCG loss for learning models
                  for a variety of vision tasks. Using the CIFAR-10
                  data set and the PASCAL VOC action recognition and
                  object detection data sets, we show that our
                  approach provides significantly better results than
                  simpler decomposable loss functions, while requiring
                  a comparable training time.},
  archiveprefix = {arXiv},
  eprint = {1604.08269},
  primaryclass = {cs.CV}
}
</pre>

<a name="kowalski-2017-applic-natur"></a><pre>
@article{<a href="index.html#kowalski-2017-applic-natur">kowalski-2017-applic-natur</a>,
  author = {Kowalski, Radoslaw and Esteve, Marc and Mikhaylov,
                  Slava J.},
  title = {Application of Natural Language Processing To
                  Determine User Satisfaction in Public Services},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.08083v1">http://arxiv.org/abs/1711.08083v1</a>},
  abstract = {Research on customer satisfaction has increased
                  substantially in recent years. However, the relative
                  importance and relationships between different
                  determinants of satisfaction remains uncertain.
                  Moreover, quantitative studies to date tend to test
                  for significance of pre-determined factors thought
                  to have an influence with no scalable means to
                  identify other causes of user satisfaction. The gaps
                  in knowledge make it difficult to use available
                  knowledge on user preference for public service
                  improvement. Meanwhile, digital technology
                  development has enabled new methods to collect user
                  feedback, for example through online forums where
                  users can comment freely on their experience. New
                  tools are needed to analyze large volumes of such
                  feedback. Use of topic models is proposed as a
                  feasible solution to aggregate open-ended user
                  opinions that can be easily deployed in the public
                  sector. Generated insights can contribute to a more
                  inclusive decision-making process in public service
                  provision. This novel methodological approach is
                  applied to a case of service reviews of
                  publicly-funded primary care practices in England.
                  Findings from the analysis of 145,000 reviews
                  covering almost 7,700 primary care centers indicate
                  that the quality of interactions with staff and
                  bureaucratic exigencies are the key issues driving
                  user satisfaction across England.},
  archiveprefix = {arXiv},
  eprint = {1711.08083},
  primaryclass = {cs.CL}
}
</pre>

<a name="wu-2017-shift"></a><pre>
@article{<a href="index.html#wu-2017-shift">wu-2017-shift</a>,
  author = {Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Jin,
                  Peter and Zhao, Sicheng and Golmant, Noah and
                  Gholaminejad, Amir and Gonzalez, Joseph and Keutzer,
                  Kurt},
  title = {Shift: A Zero Flop, Zero Parameter Alternative To
                  Spatial Convolutions},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.08141v1">http://arxiv.org/abs/1711.08141v1</a>},
  abstract = {Neural networks rely on convolutions to aggregate
                  spatial information. However, spatial convolutions
                  are expensive in terms of model size and
                  computation, both of which grow quadratically with
                  respect to kernel size. In this paper, we present a
                  parameter-free, FLOP-free "shift" operation as an
                  alternative to spatial convolutions. We fuse shifts
                  and point-wise convolutions to construct end-to-end
                  trainable shift-based modules, with a hyperparameter
                  characterizing the tradeoff between accuracy and
                  efficiency. To demonstrate the operation's efficacy,
                  we replace ResNet's 3x3 convolutions with
                  shift-based modules for improved CIFAR10 and
                  CIFAR100 accuracy using 60 \% fewer parameters; we
                  additionally demonstrate the operation's resilience
                  to parameter reduction on ImageNet, outperforming
                  ResNet family members. We finally show the shift
                  operation's applicability across domains, achieving
                  strong performance with fewer parameters on
                  classification, face verification and style
                  transfer.},
  archiveprefix = {arXiv},
  eprint = {1711.08141v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="li-2017-light-head"></a><pre>
@article{<a href="index.html#li-2017-light-head">li-2017-light-head</a>,
  author = {Li, Zeming and Peng, Chao and Yu, Gang and Zhang,
                  Xiangyu and Deng, Yangdong and Sun, Jian},
  title = {Light-Head R-Cnn: In Defense of Two-Stage Object
                  Detector},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.07264v1">http://arxiv.org/abs/1711.07264v1</a>},
  abstract = {In this paper, we first investigate why typical
                  two-stage methods are not as fast as single-stage,
                  fast detectors like YOLO and SSD. We find that
                  Faster R-CNN and R-FCN perform an intensive
                  computation after or before RoI warping. Faster
                  R-CNN involves two fully connected layers for RoI
                  recognition, while R-FCN produces a large score
                  maps. Thus, the speed of these networks is slow due
                  to the heavy-head design in the architecture. Even
                  if we significantly reduce the base model, the
                  computation cost cannot be largely decreased
                  accordingly. We propose a new two-stage detector,
                  Light-Head R-CNN, to address the shortcoming in
                  current two-stage approaches. In our design, we make
                  the head of network as light as possible, by using a
                  thin feature map and a cheap R-CNN subnet (pooling
                  and single fully-connected layer). Our ResNet-101
                  based light-head R-CNN outperforms state-of-art
                  object detectors on COCO while keeping time
                  efficiency. More importantly, simply replacing the
                  backbone with a tiny network (e.g, Xception), our
                  Light-Head R-CNN gets 30.7 mmAP at 102 FPS on COCO,
                  significantly outperforming the single-stage, fast
                  detectors like YOLO and SSD on both speed and
                  accuracy. Code will be make publicly available.},
  archiveprefix = {arXiv},
  eprint = {1711.07264v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="wang-2017-non-local"></a><pre>
@article{<a href="index.html#wang-2017-non-local">wang-2017-non-local</a>,
  author = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav
                  and He, Kaiming},
  title = {Non-Local Neural Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.07971v1">http://arxiv.org/abs/1711.07971v1</a>},
  abstract = {Both convolutional and recurrent operations are
                  building blocks that process one local neighborhood
                  at a time. In this paper, we present non-local
                  operations as a generic family of building blocks
                  for capturing long-range dependencies. Inspired by
                  the classical non-local means method in computer
                  vision, our non-local operation computes the
                  response at a position as a weighted sum of the
                  features at all positions. This building block can
                  be plugged into many computer vision architectures.
                  On the task of video classification, even without
                  any bells and whistles, our non-local models can
                  compete or outperform current competition winners on
                  both Kinetics and Charades datasets. In static image
                  recognition, our non-local models improve object
                  detection/segmentation and pose estimation on the
                  COCO suite of tasks. Code will be made available.},
  archiveprefix = {arXiv},
  eprint = {1711.07971v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="wu-2017-are-you"></a><pre>
@article{<a href="index.html#wu-2017-are-you">wu-2017-are-you</a>,
  author = {Wu, Qi and Wang, Peng and Shen, Chunhua and Reid,
                  Ian and Hengel, Anton van den},
  title = {Are You Talking To Me? Reasoned Visual Dialog
                  Generation Through Adversarial Learning},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.07613v1">http://arxiv.org/abs/1711.07613v1</a>},
  abstract = {The Visual Dialogue task requires an agent to engage
                  in a conversation about an image with a human. It
                  represents an extension of the Visual Question
                  Answering task in that the agent needs to answer a
                  question about an image, but it needs to do so in
                  light of the previous dialogue that has taken place.
                  The key challenge in Visual Dialogue is thus
                  maintaining a consistent, and natural dialogue while
                  continuing to answer questions correctly. We present
                  a novel approach that combines Reinforcement
                  Learning and Generative Adversarial Networks (GANs)
                  to generate more human-like responses to questions.
                  The GAN helps overcome the relative paucity of
                  training data, and the tendency of the typical
                  MLE-based approach to generate overly terse answers.
                  Critically, the GAN is tightly integrated into the
                  attention mechanism that generates
                  human-interpretable reasons for each answer. This
                  means that the discriminative model of the GAN has
                  the task of assessing whether a candidate answer is
                  generated by a human or not, given the provided
                  reason. This is significant because it drives the
                  generative model to produce high quality answers
                  that are well supported by the associated reasoning.
                  The method also generates the state-of-the-art
                  results on the primary benchmark.},
  archiveprefix = {arXiv},
  eprint = {1711.07613v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="gao-2017-knowl-concen"></a><pre>
@article{<a href="index.html#gao-2017-knowl-concen">gao-2017-knowl-concen</a>,
  author = {Jiyang Gao, Zijian Guo, Zhen Li and Ram},
  title = {Knowledge Concentration: Learning 100k Object
                  Classifiers in a Single Cnn},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.07607v1">http://arxiv.org/abs/1711.07607v1</a>},
  abstract = {Fine-grained image labels are desirable for many
                  computer vision applications, such as visual search
                  or mobile AI assistant. These applications rely on
                  image classification models that can produce
                  hundreds of thousands (e.g. 100K) of diversified
                  fine-grained image labels on input images. However,
                  training a network at this vocabulary scale is
                  challenging, and suffers from intolerable large
                  model size and slow training speed, which leads to
                  unsatisfying classification performance. A
                  straightforward solution would be training separate
                  expert networks (specialists), with each specialist
                  focusing on learning one specific vertical (e.g.
                  cars, birds...). However, deploying dozens of expert
                  networks in a practical system would significantly
                  increase system complexity and inference latency,
                  and consumes large amounts of computational
                  resources. To address these challenges, we propose a
                  Knowledge Concentration method, which effectively
                  transfers the knowledge from dozens of specialists
                  (multiple teacher networks) into one single model
                  (one student network) to classify 100K object
                  categories. There are three salient aspects in our
                  method: (1) a multi-teacher single-student knowledge
                  distillation framework; (2) a self-paced learning
                  mechanism to allow the student to learn from
                  different teachers at various paces; (3)
                  structurally connected layers to expand the student
                  network capacity with limited extra parameters. We
                  validate our method on OpenImage and a newly
                  collected dataset, Entity-Foto-Tree (EFT), with 100K
                  categories, and show that the proposed model
                  performs significantly better than the baseline
                  generalist model.},
  archiveprefix = {arXiv},
  eprint = {1711.07607v1},
  primaryclass = {cs.CV}
}
</pre>

<a name="liu-2017-rubys"></a><pre>
@article{<a href="index.html#liu-2017-rubys">liu-2017-rubys</a>,
  author = {Liu, Huiting and Lin, Tao and Sun, Hanfei and Lin,
                  Weijian and Chang, Chih-Wei and Zhong, Teng and
                  Rudnicky, Alexander},
  title = {Rubystar: A Non-Task-Oriented Mixture Model Dialog
                  System},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.02781v2">http://arxiv.org/abs/1711.02781v2</a>},
  abstract = {RubyStar is a dialog system designed to create
                  "human-like" conversation by combining different
                  response generation strategies. RubyStar conducts a
                  non-task-oriented conversation on general topics by
                  using an ensemble of rule-based, retrieval-based and
                  generative methods. Topic detection, engagement
                  monitoring, and context tracking are used for
                  managing interaction. Predictable elements of
                  conversation, such as the bot's backstory and simple
                  question answering are handled by separate modules.
                  We describe a rating scheme we developed for
                  evaluating response generation. We find that
                  character-level RNN is an effective generation model
                  for general responses, with proper parameter
                  settings; however other kinds of conversation topics
                  might benefit from using other models.},
  archiveprefix = {arXiv},
  eprint = {1711.02781},
  primaryclass = {cs.CL}
}
</pre>

<a name="zhang-2017-actor-critic"></a><pre>
@article{<a href="index.html#zhang-2017-actor-critic">zhang-2017-actor-critic</a>,
  author = {Zhang, Li and Sung, Flood and Liu, Feng and Xiang,
                  Tao and Gong, Shaogang and Yang, Yongxin and
                  Hospedales, Timothy M.},
  title = {Actor-Critic Sequence Training for Image Captioning},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1706.09601v2">http://arxiv.org/abs/1706.09601v2</a>},
  abstract = {Generating natural language descriptions of images
                  is an important capability for a robot or other
                  visual-intelligence driven AI agent that may need to
                  communicate with human users about what it is
                  seeing. Such image captioning methods are typically
                  trained by maximising the likelihood of ground-truth
                  annotated caption given the image. While simple and
                  easy to implement, this approach does not directly
                  maximise the language quality metrics we care about
                  such as CIDEr. In this paper we investigate training
                  image captioning methods based on actor-critic
                  reinforcement learning in order to directly optimise
                  non-differentiable quality metrics of interest. By
                  formulating a per-token advantage and value
                  computation strategy in this novel reinforcement
                  learning based captioning model, we show that it is
                  possible to achieve the state of the art performance
                  on the widely used MSCOCO benchmark.},
  archiveprefix = {arXiv},
  eprint = {1706.09601},
  primaryclass = {cs.CV}
}
</pre>

<a name="fong-2017-backp-as-funct"></a><pre>
@article{<a href="index.html#fong-2017-backp-as-funct">fong-2017-backp-as-funct</a>,
  author = {Fong, Brendan and Spivak, David I. and Tuy{\'e}ras,
                  R{\'e}my},
  title = {Backprop As Functor: A Compositional Perspective on
                  Supervised Learning},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.10455v1">http://arxiv.org/abs/1711.10455v1</a>},
  abstract = {A supervised learning algorithm searches over a set
                  of functions $A \to B$ parametrised by a space $P$
                  to find the best approximation to some ideal
                  function $f\colon A \to B$. It does this by taking
                  examples $(a,f(a)) \in A\times B$, and updating the
                  parameter according to some rule. We define a
                  category where these update rules may be composed,
                  and show that gradient descent---with respect to a
                  fixed step size and an error function satisfying a
                  certain property---defines a monoidal functor from a
                  category of parametrised functions to this category
                  of update rules. This provides a structural
                  perspective on backpropagation, as well as a broad
                  generalisation of neural networks.},
  archiveprefix = {arXiv},
  eprint = {1711.10455},
  primaryclass = {math.CT}
}
</pre>

<a name="deng-2017-infer-users"></a><pre>
@article{<a href="index.html#deng-2017-infer-users">deng-2017-infer-users</a>,
  author = {Deng, Xiaofang and Wu, Leilei and Ren, Xiaolong and
                  Jia, Chunxiao and Zhong, Yuansheng and L{\"u},
                  Linyuan},
  title = {Inferring Users' Preferences Through Leveraging
                  Their Social Relationships},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.10399v1">http://arxiv.org/abs/1711.10399v1</a>},
  abstract = {Recommender systems, inferring users' preferences
                  from their historical activities and personal
                  profiles, have been an enormous success in the last
                  several years. Most of the existing works are based
                  on the similarities of users, objects or both that
                  derived from their purchases records in the online
                  shopping platforms. Such approaches, however, are
                  facing bottlenecks when the known information is
                  limited. The extreme case is how to recommend
                  products to new users, namely the so-called
                  cold-start problem. The rise of the online social
                  networks gives us a chance to break the glass
                  ceiling. Birds of a feather flock together. Close
                  friends may have similar hidden pattern of selecting
                  products and the advices from friends are more
                  trustworthy. In this paper, we integrate the
                  individual's social relationships into recommender
                  systems and propose a new method, called Social Mass
                  Diffusion (SMD), based on a mass diffusion process
                  in the combined network of users' social network and
                  user-item bipartite network. The results show that
                  the SMD algorithm can achieve higher recommendation
                  accuracy than the Mass Diffusion (MD) purely on the
                  bipartite network. Especially, the improvement is
                  striking for small degree users. Moreover, SMD
                  provides a good solution to the cold-start problem.
                  The recommendation accuracy for new users
                  significantly higher than that of the conventional
                  popularity-based algorithm. These results may shed
                  some light on the new designs of better personalized
                  recommender systems and information services.},
  archiveprefix = {arXiv},
  eprint = {1711.10399},
  primaryclass = {cs.SI}
}
</pre>

<a name="botvinick-2017-build-machin"></a><pre>
@article{<a href="index.html#botvinick-2017-build-machin">botvinick-2017-build-machin</a>,
  author = {Botvinick, M. and Barrett, D. G. T. and Battaglia,
                  P. and Freitas, N. de and Kumaran, D. and Leibo, J.
                  Z and Lillicrap, T. and Modayil, J. and Mohamed, S.
                  and Rabinowitz, N. C. and Rezende, D. J. and
                  Santoro, A. and Schaul, T. and Summerfield, C. and
                  Wayne, G. and Weber, T. and Wierstra, D. and Legg,
                  S. and Hassabis, D.},
  title = {Building Machines That Learn and Think for
                  Themselves: Commentary on Lake Et Al., Behavioral
                  and Brain Sciences, 2017},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.08378v1">http://arxiv.org/abs/1711.08378v1</a>},
  abstract = {We agree with Lake and colleagues on their list of
                  key ingredients for building humanlike intelligence,
                  including the idea that model-based reasoning is
                  essential. However, we favor an approach that
                  centers on one additional ingredient: autonomy. In
                  particular, we aim toward agents that can both build
                  and exploit their own internal models, with minimal
                  human hand-engineering. We believe an approach
                  centered on autonomous learning has the greatest
                  chance of success as we scale toward real-world
                  complexity, tackling domains for which ready-made
                  formal models are not available. Here we survey
                  several important examples of the progress that has
                  been made toward building autonomous agents with
                  humanlike abilities, and highlight some outstanding
                  challenges.},
  archiveprefix = {arXiv},
  eprint = {1711.08378v1},
  primaryclass = {cs.AI}
}
</pre>

<a name="choi-2017-starg"></a><pre>
@article{<a href="index.html#choi-2017-starg">choi-2017-starg</a>,
  author = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and
                  Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  title = {Stargan: Unified Generative Adversarial Networks for
                  Multi-Domain Image-To-Image Translation},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1711.09020v1">http://arxiv.org/abs/1711.09020v1</a>},
  abstract = {Recent studies have shown remarkable success in
                  image-to-image translation for two domains. However,
                  existing approaches have limited scalability and
                  robustness in handling more than two domains, since
                  different models should be built independently for
                  every pair of image domains. To address this
                  limitation, we propose StarGAN, a novel and scalable
                  approach that can perform image-to-image
                  translations for multiple domains using only a
                  single model. Such a unified model architecture of
                  StarGAN allows simultaneous training of multiple
                  datasets with different domains within a single
                  network. This leads to StarGAN's superior quality of
                  translated images compared to existing models as
                  well as the novel capability of flexibly translating
                  an input image to any desired target domain. We
                  empirically demonstrate the effectiveness of our
                  approach on a facial attribute transfer and a facial
                  expression synthesis tasks.},
  archiveprefix = {arXiv},
  eprint = {1711.09020},
  primaryclass = {cs.CV}
}
</pre>

<a name="santander-vela-2017-agile-softw"></a><pre>
@article{<a href="index.html#santander-vela-2017-agile-softw">santander-vela-2017-agile-softw</a>,
  author = {Santander-Vela, Juande},
  title = {Agile Software Engineering and Systems Engineering
                  At Ska Scale},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.00061v2">http://arxiv.org/abs/1712.00061v2</a>},
  abstract = {Systems Engineering (SE) is the set of processes and
                  documentation required for successfully realising
                  large-scale engineering projects, but the classical
                  approach is not a good fit for software-intensive
                  projects, especially when the needs of the different
                  stakeholders are not fully known from the beginning,
                  and requirement priorities might change. The SKA is
                  the ultimate software-enabled telescope, with
                  enormous amounts of computing hardware and software
                  required to perform its data reduction. We give an
                  overview of the system and software engineering
                  processes in the SKA1 development, and the tension
                  between classical and agile SE.},
  archiveprefix = {arXiv},
  eprint = {1712.00061},
  primaryclass = {astro-ph.IM}
}
</pre>

<a name="zhang-2017-fast-top"></a><pre>
@article{<a href="index.html#zhang-2017-fast-top">zhang-2017-fast-top</a>,
  author = {Zhang, Fang and Wang, Xiaochen and Han, Jingfei and
                  Tang, Jie and Wang, Shiyin and Moens,
                  Marie-Francine},
  title = {Fast Top-K Area Topics Extraction With Knowledge
                  Base},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.04822v2">http://arxiv.org/abs/1710.04822v2</a>},
  abstract = {What are the most popular research topics in
                  Artificial Intelligence (AI)? We formulate the
                  problem as extracting top-$k$ topics that can best
                  represent a given area with the help of knowledge
                  base. We theoretically prove that the problem is
                  NP-hard and propose an optimization model, FastKATE,
                  to address this problem by combining both explicit
                  and latent representations for each topic. We
                  leverage a large-scale knowledge base (Wikipedia) to
                  generate topic embeddings using neural networks and
                  use this kind of representations to help capture the
                  representativeness of topics for given areas. We
                  develop a fast heuristic algorithm to efficiently
                  solve the problem with a provable error bound. We
                  evaluate the proposed model on three real-world
                  datasets. Experimental results demonstrate our
                  model's effectiveness, robustness, real-timeness
                  (return results in $$<$1$s), and its superiority
                  over several alternative methods.},
  archiveprefix = {arXiv},
  eprint = {1710.04822},
  primaryclass = {cs.AI}
}
</pre>

<a name="xiang-2017-effec-batch"></a><pre>
@article{<a href="index.html#xiang-2017-effec-batch">xiang-2017-effec-batch</a>,
  author = {Xiang, Sitao and Li, Hao},
  title = {On the Effects of Batch and Weight Normalization in
                  Generative Adversarial Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1704.03971v4">http://arxiv.org/abs/1704.03971v4</a>},
  abstract = {Generative adversarial networks (GANs) are highly
                  effective unsupervised learning frameworks that can
                  generate very sharp data, even for data such as
                  images with complex, highly multimodal
                  distributions. However GANs are known to be very
                  hard to train, suffering from problems such as mode
                  collapse and disturbing visual artifacts. Batch
                  normalization (BN) techniques have been introduced
                  to address the training. Though BN accelerates the
                  training in the beginning, our experiments show that
                  the use of BN can be unstable and negatively impact
                  the quality of the trained model. The evaluation of
                  BN and numerous other recent schemes for improving
                  GAN training is hindered by the lack of an effective
                  objective quality measure for GAN models. To address
                  these issues, we first introduce a weight
                  normalization (WN) approach for GAN training that
                  significantly improves the stability, efficiency and
                  the quality of the generated samples. To allow a
                  methodical evaluation, we introduce squared
                  Euclidean reconstruction error on a test set as a
                  new objective measure, to assess training
                  performance in terms of speed, stability, and
                  quality of generated samples. Our experiments with a
                  standard DCGAN architecture on commonly used
                  datasets (CelebA, LSUN bedroom, and CIFAR-10)
                  indicate that training using WN is generally
                  superior to BN for GANs, achieving 10 \% lower mean
                  squared loss for reconstruction and significantly
                  better qualitative results than BN. We further
                  demonstrate the stability of WN on a 21-layer ResNet
                  trained with the CelebA data set. The code for this
                  paper is available at
                  https://github.com/stormraiser/gan-weightnorm-resnet},
  archiveprefix = {arXiv},
  eprint = {1704.03971},
  primaryclass = {stat.ML}
}
</pre>

<a name="misra-2017-learn-by"></a><pre>
@article{<a href="index.html#misra-2017-learn-by">misra-2017-learn-by</a>,
  author = {Misra, Ishan and Girshick, Ross and Fergus, Rob and
                  Hebert, Martial and Gupta, Abhinav and Maaten,
                  Laurens van der},
  title = {Learning By Asking Questions},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.01238v1">http://arxiv.org/abs/1712.01238v1</a>},
  abstract = {We introduce an interactive learning framework for
                  the development and testing of intelligent visual
                  systems, called learning-by-asking (LBA). We explore
                  LBA in context of the Visual Question Answering
                  (VQA) task. LBA differs from standard VQA training
                  in that most questions are not observed during
                  training time, and the learner must ask questions it
                  wants answers to. Thus, LBA more closely mimics
                  natural learning and has the potential to be more
                  data-efficient than the traditional VQA setting. We
                  present a model that performs LBA on the CLEVR
                  dataset, and show that it automatically discovers an
                  easy-to-hard curriculum when learning interactively
                  from an oracle. Our LBA generated data consistently
                  matches or outperforms the CLEVR train data and is
                  more sample efficient. We also show that our model
                  asks questions that generalize to state-of-the-art
                  VQA models and to novel test time distributions.},
  archiveprefix = {arXiv},
  eprint = {1712.01238},
  primaryclass = {cs.CV}
}
</pre>

<a name="adami-2017-mind-as"></a><pre>
@article{<a href="index.html#adami-2017-mind-as">adami-2017-mind-as</a>,
  author = {Adami, Christoph},
  title = {The Mind As a Computational System},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.01093v1">http://arxiv.org/abs/1712.01093v1</a>},
  abstract = {The present document is an excerpt of an essay that
                  I wrote as part of my application material to
                  graduate school in Computer Science (with a focus on
                  Artificial Intelligence), in 1986. I was not invited
                  by any of the schools that received it, so I became
                  a theoretical physicist instead. The essay's full
                  title was "Some Topics in Philosophy and Computer
                  Science". I am making this text (unchanged from
                  1985, preserving the typesetting as much as
                  possible) available now in memory of Jerry Fodor,
                  whose writings had influenced me significantly at
                  the time (even though I did not always agree).},
  archiveprefix = {arXiv},
  eprint = {1712.01093},
  primaryclass = {cs.AI}
}
</pre>

<a name="billings-2017-will-human"></a><pre>
@article{<a href="index.html#billings-2017-will-human">billings-2017-will-human</a>,
  author = {Billings, Jay Jay and McCaskey, Alexander J. and
                  Vallee, Geoffroy and Watson, Greg},
  title = {Will Humans Even Write Code in 2040 and What Would
                  That Mean for Extreme Heterogeneity in Computing?},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.00676v1">http://arxiv.org/abs/1712.00676v1</a>},
  abstract = {Programming trends suggest that software development
                  will undergo a radical change in the future: the
                  combination of machine learning, artificial
                  intelligence, natural language processing, and code
                  generation technologies will improve in such a way
                  that machines, instead of humans, will write most of
                  their own code by 2040. This poses a number of
                  interesting challenges for scientific research,
                  especially as the hardware on which this Machine
                  Generated Code will run becomes extremely
                  heterogeneous. Indeed, extreme heterogeneity may
                  drive the creation of this technology because it
                  will allow humans to cope with the difficulty of
                  programming different devices efficiently and
                  easily.},
  archiveprefix = {arXiv},
  eprint = {1712.00676},
  primaryclass = {cs.SE}
}
</pre>

<a name="miller-2017-explain-ai"></a><pre>
@article{<a href="index.html#miller-2017-explain-ai">miller-2017-explain-ai</a>,
  author = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
  title = {Explainable Ai: Beware of Inmates Running the Asylum
                  Or: How I Learnt To Stop Worrying and Love the
                  Social and Behavioural Sciences},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.00547v1">http://arxiv.org/abs/1712.00547v1</a>},
  abstract = {In his seminal book `The Inmates are Running the
                  Asylum: Why High-Tech Products Drive Us Crazy And
                  How To Restore The Sanity' [2004, Sams Indianapolis,
                  IN, USA], Alan Cooper argues that a major reason why
                  software is often poorly designed (from a user
                  perspective) is that programmers are in charge of
                  design decisions, rather than interaction designers.
                  As a result, programmers design software for
                  themselves, rather than for their target audience; a
                  phenomenon he refers to as the `inmates running the
                  asylum'. This paper argues that explainable AI risks
                  a similar fate. While the re-emergence of
                  explainable AI is positive, this paper argues most
                  of us as AI researchers are building explanatory
                  agents for ourselves, rather than for the intended
                  users. But explainable AI is more likely to succeed
                  if researchers and practitioners understand, adopt,
                  implement, and improve models from the vast and
                  valuable bodies of research in philosophy,
                  psychology, and cognitive science; and if evaluation
                  of these models is focused more on people than on
                  technology. From a light scan of literature, we
                  demonstrate that there is considerable scope to
                  infuse more results from the social and behavioural
                  sciences into explainable AI, and present some key
                  results from these fields that are relevant to
                  explainable AI.},
  archiveprefix = {arXiv},
  eprint = {1712.00547},
  primaryclass = {cs.AI}
}
</pre>

<a name="kong-2017-take-it"></a><pre>
@article{<a href="index.html#kong-2017-take-it">kong-2017-take-it</a>,
  author = {Kong, Chen and Lucey, Simon},
  title = {Take It in Your Stride: Do We Need Striding in
                  Cnns?},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.02502v1">http://arxiv.org/abs/1712.02502v1</a>},
  abstract = {Since their inception, CNNs have utilized some type
                  of striding operator to reduce the overlap of
                  receptive fields and spatial dimensions. Although
                  having clear heuristic motivations (i.e. lowering
                  the number of parameters to learn) the mathematical
                  role of striding within CNN learning remains
                  unclear. This paper offers a novel and mathematical
                  rigorous perspective on the role of the striding
                  operator within modern CNNs. Specifically, we
                  demonstrate theoretically that one can always
                  represent a CNN that incorporates striding with an
                  equivalent non-striding CNN which has more filters
                  and smaller size. Through this equivalence we are
                  then able to characterize striding as an additional
                  mechanism for parameter sharing among channels, thus
                  reducing training complexity. Finally, the framework
                  presented in this paper offers a new mathematical
                  perspective on the role of striding which we hope
                  shall facilitate and simplify the future theoretical
                  analysis of CNNs.},
  archiveprefix = {arXiv},
  eprint = {1712.02502},
  primaryclass = {cs.LG}
}
</pre>

<a name="you-2017-imagen-train-minut"></a><pre>
@article{<a href="index.html#you-2017-imagen-train-minut">you-2017-imagen-train-minut</a>,
  author = {You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and
                  Demmel, James and Keutzer, Kurt},
  title = {Imagenet Training in Minutes},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1709.05011v8">http://arxiv.org/abs/1709.05011v8</a>},
  abstract = {Finishing 90-epoch ImageNet-1k training with
                  ResNet-50 on a NVIDIA M40 GPU takes 14 days. This
                  training requires 10^18 single precision operations
                  in total. On the other hand, the world's current
                  fastest supercomputer can finish 2 * 10^17 single
                  precision operations per second (Dongarra et al
                  2017, https://www.top500.org/lists/2017/06/). If we
                  can make full use of the supercomputer for DNN
                  training, we should be able to finish the 90-epoch
                  ResNet-50 training in one minute. However, the
                  current bottleneck for fast DNN training is in the
                  algorithm level. Specifically, the current batch
                  size (e.g. 512) is too small to make efficient use
                  of many processors. For large-scale DNN training, we
                  focus on using large-batch data-parallelism
                  synchronous SGD without losing accuracy in the fixed
                  epochs. The LARS algorithm (You, Gitman, Ginsburg,
                  2017, arXiv:1708.03888) enables us to scale the
                  batch size to extremely large case (e.g. 32K). We
                  finish the 100-epoch ImageNet training with AlexNet
                  in 11 minutes on 1024 CPUs. About three times faster
                  than Facebook's result (Goyal et al 2017,
                  arXiv:1706.02677), we finish the 90-epoch ImageNet
                  training with ResNet-50 in 20 minutes on 2048 KNLs
                  without losing accuracy. We got 74.7 \% top-1 test
                  accuracy in 64 epochs, which only needs 14 minutes.
                  Furthermore, when we increase the batch size to
                  above 16K, our accuracy is much higher than
                  Facebook's on corresponding batch sizes. Our source
                  code is available upon request.},
  archiveprefix = {arXiv},
  eprint = {1709.05011v8},
  primaryclass = {cs.CV}
}
</pre>

<a name="zhang-2017-shuff"></a><pre>
@article{<a href="index.html#zhang-2017-shuff">zhang-2017-shuff</a>,
  author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and
                  Sun, Jian},
  title = {Shufflenet: An Extremely Efficient Convolutional
                  Neural Network for Mobile Devices},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1707.01083v2">http://arxiv.org/abs/1707.01083v2</a>},
  abstract = {We introduce an extremely computation-efficient CNN
                  architecture named ShuffleNet, which is designed
                  specially for mobile devices with very limited
                  computing power (e.g., 10-150 MFLOPs). The new
                  architecture utilizes two new operations, pointwise
                  group convolution and channel shuffle, to greatly
                  reduce computation cost while maintaining accuracy.
                  Experiments on ImageNet classification and MS COCO
                  object detection demonstrate the superior
                  performance of ShuffleNet over other structures,
                  e.g. lower top-1 error (absolute 7.8 \%) than recent
                  MobileNet on ImageNet classification task, under the
                  computation budget of 40 MFLOPs. On an ARM-based
                  mobile device, ShuffleNet achieves ~13x actual
                  speedup over AlexNet while maintaining comparable
                  accuracy.},
  archiveprefix = {arXiv},
  eprint = {1707.01083v2},
  primaryclass = {cs.CV}
}
</pre>

<a name="agarwal-2017-deep-networ"></a><pre>
@article{<a href="index.html#agarwal-2017-deep-networ">agarwal-2017-deep-networ</a>,
  author = {Agarwal, Basant and Ramampiaro, Heri and Langseth,
                  Helge and Ruocco, Massimiliano},
  title = {A Deep Network Model for Paraphrase Detection in
                  Short Text Messages},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.02820v1">http://arxiv.org/abs/1712.02820v1</a>},
  abstract = {This paper is concerned with paraphrase detection.
                  The ability to detect similar sentences written in
                  natural language is crucial for several
                  applications, such as text mining, text
                  summarization, plagiarism detection, authorship
                  authentication and question answering. Given two
                  sentences, the objective is to detect whether they
                  are semantically identical. An important insight
                  from this work is that existing paraphrase systems
                  perform well when applied on clean texts, but they
                  do not necessarily deliver good performance against
                  noisy texts. Challenges with paraphrase detection on
                  user generated short texts, such as Twitter, include
                  language irregularity and noise. To cope with these
                  challenges, we propose a novel deep neural
                  network-based approach that relies on coarse-grained
                  sentence modeling using a convolutional neural
                  network and a long short-term memory model, combined
                  with a specific fine-grained word-level similarity
                  matching model. Our experimental results show that
                  the proposed approach outperforms existing
                  state-of-the-art approaches on user-generated noisy
                  social media data, such as Twitter texts, and
                  achieves highly competitive performance on a cleaner
                  corpus.},
  archiveprefix = {arXiv},
  eprint = {1712.02820},
  primaryclass = {cs.IR}
}
</pre>

<a name="silver-2017-master-chess"></a><pre>
@article{<a href="index.html#silver-2017-master-chess">silver-2017-master-chess</a>,
  author = {Silver, David and Hubert, Thomas and Schrittwieser,
                  Julian and Antonoglou, Ioannis and Lai, Matthew and
                  Guez, Arthur and Lanctot, Marc and Sifre, Laurent
                  and Kumaran, Dharshan and Graepel, Thore and
                  Lillicrap, Timothy and Simonyan, Karen and Hassabis,
                  Demis},
  title = {Mastering Chess and Shogi By Self-Play With a
                  General Reinforcement Learning Algorithm},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.01815v1">http://arxiv.org/abs/1712.01815v1</a>},
  abstract = {The game of chess is the most widely-studied domain
                  in the history of artificial intelligence. The
                  strongest programs are based on a combination of
                  sophisticated search techniques, domain-specific
                  adaptations, and handcrafted evaluation functions
                  that have been refined by human experts over several
                  decades. In contrast, the AlphaGo Zero program
                  recently achieved superhuman performance in the game
                  of Go, by tabula rasa reinforcement learning from
                  games of self-play. In this paper, we generalise
                  this approach into a single AlphaZero algorithm that
                  can achieve, tabula rasa, superhuman performance in
                  many challenging domains. Starting from random play,
                  and given no domain knowledge except the game rules,
                  AlphaZero achieved within 24 hours a superhuman
                  level of play in the games of chess and shogi
                  (Japanese chess) as well as Go, and convincingly
                  defeated a world-champion program in each case.},
  archiveprefix = {arXiv},
  eprint = {1712.01815v1},
  primaryclass = {cs.AI}
}
</pre>

<a name="chavdarova-2017-sgan"></a><pre>
@article{<a href="index.html#chavdarova-2017-sgan">chavdarova-2017-sgan</a>,
  author = {Chavdarova, Tatjana and Fleuret, Fran{\c{c}}ois},
  title = {Sgan: An Alternative Training of Generative
                  Adversarial Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.02330v1">http://arxiv.org/abs/1712.02330v1</a>},
  abstract = {The Generative Adversarial Networks (GANs) have
                  demonstrated impressive performance for data
                  synthesis, and are now used in a wide range of
                  computer vision tasks. In spite of this success,
                  they gained a reputation for being difficult to
                  train, what results in a time-consuming and
                  human-involved development process to use them. We
                  consider an alternative training process, named
                  SGAN, in which several adversarial "local" pairs of
                  networks are trained independently so that a
                  "global" supervising pair of networks can be trained
                  against them. The goal is to train the global pair
                  with the corresponding ensemble opponent for
                  improved performances in terms of mode coverage.
                  This approach aims at increasing the chances that
                  learning will not stop for the global pair,
                  preventing both to be trapped in an unsatisfactory
                  local minimum, or to face oscillations often
                  observed in practice. To guarantee the latter, the
                  global pair never affects the local ones. The rules
                  of SGAN training are thus as follows: the global
                  generator and discriminator are trained using the
                  local discriminators and generators, respectively,
                  whereas the local networks are trained with their
                  fixed local opponent. Experimental results on both
                  toy and real-world problems demonstrate that this
                  approach outperforms standard training in terms of
                  better mitigating mode collapse, stability while
                  converging and that it surprisingly, increases the
                  convergence speed as well.},
  archiveprefix = {arXiv},
  eprint = {1712.02330v1},
  primaryclass = {stat.ML}
}
</pre>

<a name="ramachandran-2017-autom"></a><pre>
@article{<a href="index.html#ramachandran-2017-autom">ramachandran-2017-autom</a>,
  author = {Ramachandran, Prabhu},
  title = {Automan: a Simple, Python-Based, Automation
                  Framework for Numerical Computing},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.04786v1">http://arxiv.org/abs/1712.04786v1</a>},
  abstract = {We present a simple framework that allows a
                  researcher to automate their computational
                  simulations. In particular the framework facilitates
                  assembling several long-running computations and
                  producing various plots as a result of these
                  computations. The framework makes it possible to
                  reproduce every figure made for a publication with a
                  single command. It also allows one to distribute the
                  computations across a network of computers. The
                  framework has been used to write a research paper in
                  the area of numerical computing. This paper
                  discusses the benefits of such a system both for the
                  researcher and to the research area in general.},
  archiveprefix = {arXiv},
  eprint = {1712.04786},
  primaryclass = {cs.OH}
}
</pre>

<a name="lillis-2017-hierar-bloom"></a><pre>
@article{<a href="index.html#lillis-2017-hierar-bloom">lillis-2017-hierar-bloom</a>,
  author = {Lillis, David and Breitinger, Frank and Scanlon,
                  Mark},
  title = {Hierarchical Bloom Filter Trees for Approximate
                  Matching},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.04544v1">http://arxiv.org/abs/1712.04544v1</a>},
  abstract = {Bytewise approximate matching algorithms have in
                  recent years shown significant promise in de-
                  tecting files that are similar at the byte level.
                  This is very useful for digital forensic
                  investigators, who are regularly faced with the
                  problem of searching through a seized device for
                  pertinent data. A common scenario is where an
                  investigator is in possession of a collection of
                  "known-illegal" files (e.g. a collection of child
                  abuse material) and wishes to find whether copies of
                  these are stored on the seized device. Approximate
                  matching addresses shortcomings in traditional
                  hashing, which can only find identical files, by
                  also being able to deal with cases of merged files,
                  embedded files, partial files, or if a file has been
                  changed in any way. Most approximate matching
                  algorithms work by comparing pairs of files, which
                  is not a scalable approach when faced with large
                  corpora. This paper demonstrates the effectiveness
                  of using a "Hierarchical Bloom Filter Tree" (HBFT)
                  data structure to reduce the running time of
                  collection-against-collection matching, with a
                  specific focus on the MRSH-v2 algorithm. Three
                  experiments are discussed, which explore the effects
                  of different configurations of HBFTs. The proposed
                  approach dramatically reduces the number of pairwise
                  comparisons required, and demonstrates substantial
                  speed gains, while maintaining effectiveness.},
  archiveprefix = {arXiv},
  eprint = {1712.04544},
  primaryclass = {cs.CR}
}
</pre>

<a name="svenstrup-2017-hash-embed"></a><pre>
@article{<a href="index.html#svenstrup-2017-hash-embed">svenstrup-2017-hash-embed</a>,
  author = {Svenstrup, Dan and Hansen, Jonas Meinertz and
                  Winther, Ole},
  title = {Hash Embeddings for Efficient Word Representations},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1709.03933v1">http://arxiv.org/abs/1709.03933v1</a>},
  abstract = {We present hash embeddings, an efficient method for
                  representing words in a continuous vector form. A
                  hash embedding may be seen as an interpolation
                  between a standard word embedding and a word
                  embedding created using a random hash function (the
                  hashing trick). In hash embeddings each token is
                  represented by $k$ $d$-dimensional embeddings
                  vectors and one $k$ dimensional weight vector. The
                  final $d$ dimensional representation of the token is
                  the product of the two. Rather than fitting the
                  embedding vectors for each token these are selected
                  by the hashing trick from a shared pool of $B$
                  embedding vectors. Our experiments show that hash
                  embeddings can easily deal with huge vocabularies
                  consisting of millions of tokens. When using a hash
                  embedding there is no need to create a dictionary
                  before training nor to perform any kind of
                  vocabulary pruning after training. We show that
                  models trained using hash embeddings exhibit at
                  least the same level of performance as models
                  trained using regular embeddings across a wide range
                  of tasks. Furthermore, the number of parameters
                  needed by such an embedding is only a fraction of
                  what is required by a regular embedding. Since
                  standard embeddings and embeddings constructed using
                  the hashing trick are actually just special cases of
                  a hash embedding, hash embeddings can be considered
                  an extension and improvement over the existing
                  regular embedding types.},
  archiveprefix = {arXiv},
  eprint = {1709.03933},
  primaryclass = {cs.CL}
}
</pre>

<a name="bocklisch-2017-rasa"></a><pre>
@article{<a href="index.html#bocklisch-2017-rasa">bocklisch-2017-rasa</a>,
  author = {Bocklisch, Tom and Faulker, Joey and Pawlowski, Nick
                  and Nichol, Alan},
  title = {Rasa: Open Source Language Understanding and
                  Dialogue Management},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.05181v1">http://arxiv.org/abs/1712.05181v1</a>},
  abstract = {We introduce a pair of tools, Rasa NLU and Rasa
                  Core, which are open source python libraries for
                  building conversational software. Their purpose is
                  to make machine-learning based dialogue management
                  and language understanding accessible to
                  non-specialist software developers. In terms of
                  design philosophy, we aim for ease of use, and
                  bootstrapping from minimal (or no) initial training
                  data. Both packages are extensively documented and
                  ship with a comprehensive suite of tests. The code
                  is available at https://github.com/RasaHQ/},
  archiveprefix = {arXiv},
  eprint = {1712.05181},
  primaryclass = {cs.CL}
}
</pre>

<a name="meyer-2017-fourt-years"></a><pre>
@article{<a href="index.html#meyer-2017-fourt-years">meyer-2017-fourt-years</a>,
  author = {Meyer, Bertrand},
  title = {Fourteen Years of Software Engineering At Eth
                  Zurich},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.05078v1">http://arxiv.org/abs/1712.05078v1</a>},
  abstract = {A Chair of Software Engineering existed at ETH
                  Zurich, the Swiss Federal Insti-tute of Technology,
                  from 1 October 2001 to 31 January 2016, under my
                  leader-ship. Our work, summarized here, covered a
                  wide range of theoretical and practi-cal topics,
                  with object technology in the Eiffel method as the
                  unifying thread .},
  archiveprefix = {arXiv},
  eprint = {1712.05078},
  primaryclass = {cs.SE}
}
</pre>

<a name="zhao-2017-lever-long"></a><pre>
@article{<a href="index.html#zhao-2017-lever-long">zhao-2017-lever-long</a>,
  author = {Zhao, Wei and Wang, Benyou and Ye, Jianbo and Gao,
                  Yongqiang and Yang, Min and Zhao, Zhou and Chen,
                  Xiaojun},
  title = {Leveraging Long and Short-Term Information in
                  Content-Aware Movie Recommendation},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09059v2">http://arxiv.org/abs/1712.09059v2</a>},
  abstract = {Movie recommendation systems provide users with
                  ranked lists of movies based on individual's
                  preferences and constraints. Two types of models are
                  commonly used to generate ranking results: long-term
                  models and session-based models. While long-term
                  models represent the interactions between users and
                  movies that are supposed to change slowly across
                  time, session-based models encode the information of
                  users' interests and changing dynamics of movies'
                  attributes in short terms. In this paper, we propose
                  an LSIC model, leveraging Long and Short-term
                  Information in Content-aware movie recommendation
                  using adversarial training. In the adversarial
                  process, we train a generator as an agent of
                  reinforcement learning which recommends the next
                  movie to a user sequentially. We also train a
                  discriminator which attempts to distinguish the
                  generated list of movies from the real records. The
                  poster information of movies is integrated to
                  further improve the performance of movie
                  recommendation, which is specifically essential when
                  few ratings are available. The experiments
                  demonstrate that the proposed model has robust
                  superiority over competitors and sets the
                  state-of-the-art. We will release the source code of
                  this work after publication.},
  archiveprefix = {arXiv},
  eprint = {1712.09059},
  primaryclass = {cs.IR}
}
</pre>

<a name="maturana-2017-docum-spann"></a><pre>
@article{<a href="index.html#maturana-2017-docum-spann">maturana-2017-docum-spann</a>,
  author = {Maturana, Francisco and Riveros, Cristian and
                  Vrgo{\v{c}}, Domagoj},
  title = {Document Spanners for Extracting Incomplete
                  Information: Expressiveness and Complexity},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1707.00827v2">http://arxiv.org/abs/1707.00827v2</a>},
  abstract = {Rule-based information extraction has lately
                  received a fair amount of attention from the
                  database community, with several languages appearing
                  in the last few years. Although information
                  extraction systems are intended to deal with
                  semistructured data, all language proposals
                  introduced so far are designed to output relations,
                  thus making them incapable of handling incomplete
                  information. To remedy the situation, we propose to
                  extend information extraction languages with the
                  ability to use mappings, thus allowing us to work
                  with documents which have missing or optional parts.
                  Using this approach, we simplify the semantics of
                  regex formulas and extraction rules, two previously
                  defined methods for extracting information, extend
                  them with the ability to handle incomplete data, and
                  study how they compare in terms of expressive power.
                  We also study computational properties of these
                  languages, focusing on the query enumeration
                  problem, as well as satisfiability and containment.},
  archiveprefix = {arXiv},
  eprint = {1707.00827},
  primaryclass = {cs.DB}
}
</pre>

<a name="lehman-2017-safe-mutat"></a><pre>
@article{<a href="index.html#lehman-2017-safe-mutat">lehman-2017-safe-mutat</a>,
  author = {Lehman, Joel and Chen, Jay and Clune, Jeff and
                  Stanley, Kenneth O.},
  title = {Safe Mutations for Deep and Recurrent Neural
                  Networks Through Output Gradients},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.06563v1">http://arxiv.org/abs/1712.06563v1</a>},
  abstract = {While neuroevolution (evolving neural networks) has
                  a successful track record across a variety of
                  domains from reinforcement learning to artificial
                  life, it is rarely applied to large, deep neural
                  networks. A central reason is that while random
                  mutation generally works in low dimensions, a random
                  perturbation of thousands or millions of weights is
                  likely to break existing functionality, providing no
                  learning signal even if some individual weight
                  changes were beneficial. This paper proposes a
                  solution by introducing a family of safe mutation
                  (SM) operators that aim within the mutation operator
                  itself to find a degree of change that does not
                  alter network behavior too much, but still
                  facilitates exploration. Importantly, these SM
                  operators do not require any additional interactions
                  with the environment. The most effective SM variant
                  capitalizes on the intriguing opportunity to scale
                  the degree of mutation of each individual weight
                  according to the sensitivity of the network's
                  outputs to that weight, which requires computing the
                  gradient of outputs with respect to the weights
                  (instead of the gradient of error, as in
                  conventional deep learning). This safe mutation
                  through gradients (SM-G) operator dramatically
                  increases the ability of a simple genetic
                  algorithm-based neuroevolution method to find
                  solutions in high-dimensional domains that require
                  deep and/or recurrent neural networks (which tend to
                  be particularly brittle to mutation), including
                  domains that require processing raw pixels. By
                  improving our ability to evolve deep neural
                  networks, this new safer approach to mutation
                  expands the scope of domains amenable to
                  neuroevolution.},
  archiveprefix = {arXiv},
  eprint = {1712.06563},
  primaryclass = {cs.NE}
}
</pre>

<a name="ghaffari-2017-improv-distr"></a><pre>
@article{<a href="index.html#ghaffari-2017-improv-distr">ghaffari-2017-improv-distr</a>,
  author = {Ghaffari, Mohsen and Li, Jason},
  title = {Improved Distributed Algorithms for Exact Shortest
                  Paths},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09121v1">http://arxiv.org/abs/1712.09121v1</a>},
  abstract = {Computing shortest paths is one of the central
                  problems in the theory of distributed computing. For
                  the last few years, substantial progress has been
                  made on the approximate single source shortest paths
                  problem, culminating in an algorithm of Henzinger,
                  Krinninger, and Nanongkai [STOC'16] which
                  deterministically computes $(1+o(1))$-approximate
                  shortest paths in $\tilde O(D+\sqrt n)$ time, where
                  $D$ is the hop-diameter of the graph. Up to
                  logarithmic factors, this time complexity is
                  optimal, matching the lower bound of Das Sarma et
                  al. [STOC'11]. The question of exact shortest paths
                  however saw no algorithmic progress for decades,
                  until the recent breakthrough of Elkin [STOC'17],
                  which established a sublinear-time algorithm for
                  exact single source shortest paths on undirected
                  graphs. Shortly after, Huang et al. [FOCS'17]
                  provided improved algorithms for exact all pairs
                  shortest paths problem on directed graphs. In this
                  paper, we present a new single-source shortest path
                  algorithm with complexity $\tilde
                  O(n^{3/4}D^{1/4})$. For polylogarithmic $D$, this
                  improves on Elkin's $\tilde{O}(n^{5/6})$ bound and
                  gets closer to the $\tilde{\Omega}(n^{1/2})$ lower
                  bound of Peleg and Rubinovich [FOCS'99]. For larger
                  values of $D$, we present an improved variant of our
                  algorithm which achieves complexity $\tilde{O}\left(
                  n^{3/4+o(1)}+ \min\{
                  n^{3/4}D^{1/6},n^{6/7}\}+D\right)$, and thus
                  compares favorably with Elkin's bound of
                  $\tilde{O}(n^{5/6} + n^{2/3}D^{1/3} + D ) $ in
                  essentially the entire range of parameters. This
                  algorithm provides also a qualitative improvement,
                  because it works for the more challenging case of
                  directed graphs (i.e., graphs where the two
                  directions of an edge can have different weights),
                  constituting the first sublinear-time algorithm for
                  directed graphs. Our algorithm also extends to the
                  case of exact $\kappa$-source shortest paths...},
  archiveprefix = {arXiv},
  eprint = {1712.09121},
  primaryclass = {cs.DC}
}
</pre>

<a name="andrychowicz-2016-learn-to"></a><pre>
@article{<a href="index.html#andrychowicz-2016-learn-to">andrychowicz-2016-learn-to</a>,
  author = {Andrychowicz, Marcin and Denil, Misha and Gomez,
                  Sergio and Hoffman, Matthew W. and Pfau, David and
                  Schaul, Tom and Shillingford, Brendan and Freitas,
                  Nando de},
  title = {Learning To Learn By Gradient Descent By Gradient
                  Descent},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1606.04474v2">http://arxiv.org/abs/1606.04474v2</a>},
  abstract = {The move from hand-designed features to learned
                  features in machine learning has been wildly
                  successful. In spite of this, optimization
                  algorithms are still designed by hand. In this paper
                  we show how the design of an optimization algorithm
                  can be cast as a learning problem, allowing the
                  algorithm to learn to exploit structure in the
                  problems of interest in an automatic way. Our
                  learned algorithms, implemented by LSTMs, outperform
                  generic, hand-designed competitors on the tasks for
                  which they are trained, and also generalize well to
                  new tasks with similar structure. We demonstrate
                  this on a number of tasks, including simple convex
                  problems, training neural networks, and styling
                  images with neural art.},
  archiveprefix = {arXiv},
  eprint = {1606.04474v2},
  primaryclass = {cs.NE}
}
</pre>

<a name="chen-2017-cnn-is"></a><pre>
@article{<a href="index.html#chen-2017-cnn-is">chen-2017-cnn-is</a>,
  author = {Chen, Qiming and Wu, Ren},
  title = {Cnn Is All You Need},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09662v1">http://arxiv.org/abs/1712.09662v1</a>},
  abstract = {The Convolution Neural Network (CNN) has
                  demonstrated the unique advantage in audio, image
                  and text learning; recently it has also challenged
                  Recurrent Neural Networks (RNNs) with long
                  short-term memory cells (LSTM) in
                  sequence-to-sequence learning, since the
                  computations involved in CNN are easily
                  parallelizable whereas those involved in RNN are
                  mostly sequential, leading to a performance
                  bottleneck. However, unlike RNN, the native CNN
                  lacks the history sensitivity required for sequence
                  transformation; therefore enhancing the sequential
                  order awareness, or position-sensitivity, becomes
                  the key to make CNN the general deep learning model.
                  In this work we introduce an extended CNN model with
                  strengthen position-sensitivity, called PoseNet. A
                  notable feature of PoseNet is the asymmetric
                  treatment of position information in the encoder and
                  the decoder. Experiments shows that PoseNet allows
                  us to improve the accuracy of CNN based
                  sequence-to-sequence learning significantly,
                  achieving around 33-36 BLEU scores on the WMT 2014
                  English-to-German translation task, and around 44-46
                  BLEU scores on the English-to-French translation
                  task.},
  archiveprefix = {arXiv},
  eprint = {1712.09662v1},
  primaryclass = {cs.CL}
}
</pre>

<a name="grewal-2017-chall-detec"></a><pre>
@article{<a href="index.html#grewal-2017-chall-detec">grewal-2017-chall-detec</a>,
  author = {Grewal, Karan and Truong, Khai N.},
  title = {On the Challenges of Detecting Rude Conversational
                  Behaviour},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09929v1">http://arxiv.org/abs/1712.09929v1</a>},
  abstract = {In this study, we aim to identify moments of
                  rudeness between two individuals. In particular, we
                  segment all occurrences of rudeness in conversations
                  into three broad, distinct categories and try to
                  identify each. We show how machine learning
                  algorithms can be used to identify rudeness based on
                  acoustic and semantic signals extracted from
                  conversations. Furthermore, we make note of our
                  shortcomings in this task and highlight what makes
                  this problem inherently difficult. Finally, we
                  provide next steps which are needed to ensure
                  further success in identifying rudeness in
                  conversations.},
  archiveprefix = {arXiv},
  eprint = {1712.09929v1},
  primaryclass = {cs.HC}
}
</pre>

<a name="ghosh-2017-robus-loss"></a><pre>
@article{<a href="index.html#ghosh-2017-robus-loss">ghosh-2017-robus-loss</a>,
  author = {Ghosh, Aritra and Kumar, Himanshu and Sastry, P. S.},
  title = {Robust Loss Functions Under Label Noise for Deep
                  Neural Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09482v1">http://arxiv.org/abs/1712.09482v1</a>},
  abstract = {In many applications of classifier learning,
                  training data suffers from label noise. Deep
                  networks are learned using huge training data where
                  the problem of noisy labels is particularly
                  relevant. The current techniques proposed for
                  learning deep networks under label noise focus on
                  modifying the network architecture and on algorithms
                  for estimating true labels from noisy labels. An
                  alternate approach would be to look for loss
                  functions that are inherently noise-tolerant. For
                  binary classification there exist theoretical
                  results on loss functions that are robust to label
                  noise. In this paper, we provide some sufficient
                  conditions on a loss function so that risk
                  minimization under that loss function would be
                  inherently tolerant to label noise for multiclass
                  classification problems. These results generalize
                  the existing results on noise-tolerant loss
                  functions for binary classification. We study some
                  of the widely used loss functions in deep networks
                  and show that the loss function based on mean
                  absolute value of error is inherently robust to
                  label noise. Thus standard back propagation is
                  enough to learn the true classifier even under label
                  noise. Through experiments, we illustrate the
                  robustness of risk minimization with such loss
                  functions for learning neural networks.},
  archiveprefix = {arXiv},
  eprint = {1712.09482v1},
  primaryclass = {stat.ML}
}
</pre>

<a name="lampinen-2017-one-shot"></a><pre>
@article{<a href="index.html#lampinen-2017-one-shot">lampinen-2017-one-shot</a>,
  author = {Lampinen, Andrew K. and McClelland, James L.},
  title = {One-Shot and Few-Shot Learning of Word Embeddings},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.10280v2">http://arxiv.org/abs/1710.10280v2</a>},
  abstract = {Standard deep learning systems require thousands or
                  millions of examples to learn a concept, and cannot
                  integrate new concepts easily. By contrast, humans
                  have an incredible ability to do one-shot or
                  few-shot learning. For instance, from just hearing a
                  word used in a sentence, humans can infer a great
                  deal about it, by leveraging what the syntax and
                  semantics of the surrounding words tells us. Here,
                  we draw inspiration from this to highlight a simple
                  technique by which deep recurrent networks can
                  similarly exploit their prior knowledge to learn a
                  useful representation for a new word from little
                  data. This could make natural language processing
                  systems much more flexible, by allowing them to
                  learn continually from the new words they
                  encounter.},
  archiveprefix = {arXiv},
  eprint = {1710.10280},
  primaryclass = {cs.CL}
}
</pre>

<a name="shalaby-2018-beyon-word-embed"></a><pre>
@article{<a href="index.html#shalaby-2018-beyon-word-embed">shalaby-2018-beyon-word-embed</a>,
  author = {Shalaby, Walid and Zadrozny, Wlodek and Jin,
                  Hongxia},
  title = {Beyond Word Embeddings: Learning Entity and Concept
                  Representations From Large Scale Knowledge Bases},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.00388v1">http://arxiv.org/abs/1801.00388v1</a>},
  abstract = {Text representation using neural word embeddings has
                  proven efficacy in many NLP applications. Recently,
                  a lot of research interest goes beyond word
                  embeddings by adapting the traditional word
                  embedding models to learn vectors of multiword
                  expressions (concepts/entities). However, current
                  methods are limited to textual knowledge bases only
                  (e.g., Wikipedia). In this paper, we propose a novel
                  approach for learning concept vectors from two large
                  scale knowledge bases (Wikipedia, and Probase). We
                  adapt the skip-gram model to seamlessly learn from
                  the knowledge in Wikipedia text and Probase concept
                  graph. We evaluate our concept embedding models
                  intrinsically on two tasks: 1) analogical reasoning
                  where we achieve a state-of-the-art performance of
                  91 \% on semantic analogies, 2) concept
                  categorization where we achieve a state-of-the-art
                  performance on two benchmark datasets achieving
                  categorization accuracy of 100 \% on one and 98 \%
                  on the other. Additionally, we present a case study
                  to extrinsically evaluate our model on unsupervised
                  argument type identification for neural semantic
                  parsing. We demonstrate the competitive accuracy of
                  our unsupervised method and its ability to better
                  generalize to out of vocabulary entity mentions
                  compared to the tedious and error prone methods
                  which depend on gazetteers and regular expressions.},
  archiveprefix = {arXiv},
  eprint = {1801.00388},
  primaryclass = {cs.CL}
}
</pre>

<a name="poggio-2017-theor-deep"></a><pre>
@article{<a href="index.html#poggio-2017-theor-deep">poggio-2017-theor-deep</a>,
  author = {Poggio, Tomaso and Kawaguchi, Kenji and Liao, Qianli
                  and Miranda, Brando and Rosasco, Lorenzo and Boix,
                  Xavier and Hidary, Jack and Mhaskar, Hrushikesh},
  title = {Theory of Deep Learning Iii: Explaining the
                  Non-Overfitting Puzzle},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1801.00173v1">http://arxiv.org/abs/1801.00173v1</a>},
  abstract = {A main puzzle of deep networks revolves around the
                  absence of overfitting despite overparametrization
                  and despite the large capacity demonstrated by zero
                  training error on randomly labeled data. In this
                  note, we show that the dynamical systems associated
                  with gradient descent minimization of nonlinear
                  networks behave near zero stable minima of the
                  empirical error as gradient system in a quadratic
                  potential with degenerate Hessian. The proposition
                  is supported by theoretical and numerical results,
                  under the assumption of stable minima of the
                  gradient. Our proposition provides the extension to
                  deep networks of key properties of gradient descent
                  methods for linear networks, that as, suggested in
                  (1), can be the key to understand generalization.
                  Gradient descent enforces a form of implicit
                  regularization controlled by the number of
                  iterations, and asymptotically converging to the
                  minimum norm solution. This implies that there is
                  usually an optimum early stopping that avoids
                  overfitting of the loss (this is relevant mainly for
                  regression). For classification, the asymptotic
                  convergence to the minimum norm solution implies
                  convergence to the maximum margin solution which
                  guarantees good classification error for "low noise"
                  datasets. The implied robustness to
                  overparametrization has suggestive implications for
                  the robustness of deep hierarchically local networks
                  to variations of the architecture with respect to
                  the curse of dimensionality.},
  archiveprefix = {arXiv},
  eprint = {1801.00173},
  primaryclass = {cs.LG}
}
</pre>

<a name="holzinger-2017-what-do"></a><pre>
@article{<a href="index.html#holzinger-2017-what-do">holzinger-2017-what-do</a>,
  author = {Holzinger, Andreas and Biemann, Chris and Pattichis,
                  Constantinos S. and Kell, Douglas B.},
  title = {What Do We Need To Build Explainable Ai Systems for
                  the Medical Domain?},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.09923v1">http://arxiv.org/abs/1712.09923v1</a>},
  abstract = {Artificial intelligence (AI) generally and machine
                  learning (ML) specifically demonstrate impressive
                  practical success in many different application
                  domains, e.g. in autonomous driving, speech
                  recognition, or recommender systems. Deep learning
                  approaches, trained on extremely large data sets or
                  using reinforcement learning methods have even
                  exceeded human performance in visual tasks,
                  particularly on playing games such as Atari, or
                  mastering the game of Go. Even in the medical domain
                  there are remarkable results. The central problem of
                  such models is that they are regarded as black-box
                  models and even if we understand the underlying
                  mathematical principles, they lack an explicit
                  declarative knowledge representation, hence have
                  difficulty in generating the underlying explanatory
                  structures. This calls for systems enabling to make
                  decisions transparent, understandable and
                  explainable. A huge motivation for our approach are
                  rising legal and privacy aspects. The new European
                  General Data Protection Regulation entering into
                  force on May 25th 2018, will make black-box
                  approaches difficult to use in business. This does
                  not imply a ban on automatic learning approaches or
                  an obligation to explain everything all the time,
                  however, there must be a possibility to make the
                  results re-traceable on demand. In this paper we
                  outline some of our research topics in the context
                  of the relatively new area of explainable-AI with a
                  focus on the application in medicine, which is a
                  very special domain. This is due to the fact that
                  medical professionals are working mostly with
                  distributed heterogeneous and complex sources of
                  data. In this paper we concentrate on three sources:
                  images, *omics data and text. We argue that research
                  in explainable-AI would generally help to facilitate
                  the implementation of AI/ML in the medical domain,
                  and specifically help to facilitate transparency and
                  trust.},
  archiveprefix = {arXiv},
  eprint = {1712.09923v1},
  primaryclass = {cs.AI}
}
</pre>

<a name="schulze-2018-vizdoom"></a><pre>
@article{<a href="index.html#schulze-2018-vizdoom">schulze-2018-vizdoom</a>,
  author = {Schulze, Christopher and Schulze, Marcus},
  title = {Vizdoom: Drqn With Prioritized Experience Replay,
                  Double-Q Learning, & Snapshot Ensembling},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01000v1">http://arxiv.org/abs/1801.01000v1</a>},
  abstract = {ViZDoom is a robust, first-person shooter
                  reinforcement learning environment, characterized by
                  a significant degree of latent state information. In
                  this paper, double-Q learning and prioritized
                  experience replay methods are tested under a certain
                  ViZDoom combat scenario using a competitive deep
                  recurrent Q-network (DRQN) architecture. In
                  addition, an ensembling technique known as snapshot
                  ensembling is employed using a specific annealed
                  learning rate to observe differences in ensembling
                  efficacy under these two methods. Annealed learning
                  rates are important in general to the training of
                  deep neural network models, as they shake up the
                  status-quo and counter a model's tending towards
                  local optima. While both variants show performance
                  exceeding those of built-in AI agents of the game,
                  the known stabilizing effects of double-Q learning
                  are illustrated, and priority experience replay is
                  again validated in its usefulness by showing
                  immediate results early on in agent development,
                  with the caveat that value overestimation is
                  accelerated in this case. In addition, some unique
                  behaviors are observed to develop for priority
                  experience replay (PER) and double-Q (DDQ) variants,
                  and snapshot ensembling of both PER and DDQ proves a
                  valuable method for improving performance of the
                  ViZDoom Marine.},
  archiveprefix = {arXiv},
  eprint = {1801.01000},
  primaryclass = {cs.AI}
}
</pre>

<a name="mao-2018-deepj"></a><pre>
@article{<a href="index.html#mao-2018-deepj">mao-2018-deepj</a>,
  author = {Mao, Huanru Henry and Shin, Taylor and Cottrell,
                  Garrison W.},
  title = {Deepj: Style-Specific Music Generation},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.00887v1">http://arxiv.org/abs/1801.00887v1</a>},
  abstract = {Recent advances in deep neural networks have enabled
                  algorithms to compose music that is comparable to
                  music composed by humans. However, few algorithms
                  allow the user to generate music with tunable
                  parameters. The ability to tune properties of
                  generated music will yield more practical benefits
                  for aiding artists, filmmakers, and composers in
                  their creative tasks. In this paper, we introduce
                  DeepJ - an end-to-end generative model that is
                  capable of composing music conditioned on a specific
                  mixture of composer styles. Our innovations include
                  methods to learn musical style and music dynamics.
                  We use our model to demonstrate a simple technique
                  for controlling the style of generated music as a
                  proof of concept. Evaluation of our model using
                  human raters shows that we have improved over the
                  Biaxial LSTM approach.},
  archiveprefix = {arXiv},
  eprint = {1801.00887},
  primaryclass = {cs.SD}
}
</pre>

<a name="marcus-2018-deep-learn"></a><pre>
@article{<a href="index.html#marcus-2018-deep-learn">marcus-2018-deep-learn</a>,
  author = {Marcus, Gary},
  title = {Deep Learning: A Critical Appraisal},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.00631v1">http://arxiv.org/abs/1801.00631v1</a>},
  abstract = {Although deep learning has historical roots going
                  back decades, neither the term "deep learning" nor
                  the approach was popular just over five years ago,
                  when the field was reignited by papers such as
                  Krizhevsky, Sutskever and Hinton's now classic
                  (2012) deep network model of Imagenet. What has the
                  field discovered in the five subsequent years?
                  Against a background of considerable progress in
                  areas such as speech recognition, image recognition,
                  and game playing, and considerable enthusiasm in the
                  popular press, I present ten concerns for deep
                  learning, and suggest that deep learning must be
                  supplemented by other techniques if we are to reach
                  artificial general intelligence.},
  archiveprefix = {arXiv},
  eprint = {1801.00631v1},
  primaryclass = {cs.AI}
}
</pre>

<a name="salehinejad-2017-recen-advan"></a><pre>
@article{<a href="index.html#salehinejad-2017-recen-advan">salehinejad-2017-recen-advan</a>,
  author = {Salehinejad, Hojjat and Baarbe, Julianne and Sankar,
                  Sharan and Barfett, Joseph and Colak, Errol and
                  Valaee, Shahrokh},
  title = {Recent Advances in Recurrent Neural Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1801.01078v1">http://arxiv.org/abs/1801.01078v1</a>},
  abstract = {Recurrent neural networks (RNNs) are capable of
                  learning features and long term dependencies from
                  sequential and time-series data. The RNNs have a
                  stack of non-linear units where at least one
                  connection between units forms a directed cycle. A
                  well-trained RNN can model any dynamical system;
                  however, training RNNs is mostly plagued by issues
                  in learning long-term dependencies. In this paper,
                  we present a survey on RNNs and several new advances
                  for newcomers and professionals in the field. The
                  fundamentals and recent advances are explained and
                  the research challenges are introduced.},
  archiveprefix = {arXiv},
  eprint = {1801.01078v1},
  primaryclass = {cs.NE}
}
</pre>

<a name="cheng-2017-survey-model"></a><pre>
@article{<a href="index.html#cheng-2017-survey-model">cheng-2017-survey-model</a>,
  author = {Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang,
                  Tao},
  title = {A Survey of Model Compression and Acceleration for
                  Deep Neural Networks},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1710.09282v5">http://arxiv.org/abs/1710.09282v5</a>},
  abstract = {Deep convolutional neural networks (CNNs) have
                  recently achieved great success in many visual
                  recognition tasks. However, existing deep
                  convolutional neural network models are
                  computationally expensive and memory intensive,
                  hindering their deployment in devices with low
                  memory resources or in applications with strict
                  latency requirements. Therefore, a natural thought
                  is to perform model compression and acceleration in
                  deep networks without significantly decreasing the
                  model performance. During the past few years,
                  tremendous progresses have been made in this area.
                  In this paper, we survey the recent advanced
                  techniques for compacting and accelerating CNNs
                  model developed. These techniques are roughly
                  categorized into four schemes: parameter pruning and
                  sharing, low-rank factorization, transfered/compact
                  convolutional filters and knowledge distillation.
                  Methods of parameter pruning and sharing will be
                  described at the beginning, after that the other
                  techniques will be introduced. For each scheme, we
                  provide insightful analysis regarding the
                  performance, related applications, advantages and
                  drawbacks etc. Then we will go through a few very
                  recent additional successful methods, for example,
                  dynamic networks and stochastic depths networks.
                  After that, we survey the evaluation matrix, main
                  datasets used for evaluating the model performance
                  and recent benchmarking efforts. Finally we conclude
                  this paper, discuss remaining challenges and
                  possible directions in this topic.},
  archiveprefix = {arXiv},
  eprint = {1710.09282v5},
  primaryclass = {cs.LG}
}
</pre>

<a name="yu-2017-artif-intel-statis"></a><pre>
@article{<a href="index.html#yu-2017-artif-intel-statis">yu-2017-artif-intel-statis</a>,
  author = {Yu, Bin and Kumbier, Karl},
  title = {Artificial Intelligence and Statistics},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1712.03779v1">http://arxiv.org/abs/1712.03779v1</a>},
  abstract = {Artificial intelligence (AI) is intrinsically
                  data-driven. It calls for the application of
                  statistical concepts through human-machine
                  collaboration during generation of data, development
                  of algorithms, and evaluation of results. This paper
                  discusses how such human-machine collaboration can
                  be approached through the statistical concepts of
                  population, question of interest, representativeness
                  of training data, and scrutiny of results (PQRS).
                  The PQRS workflow provides a conceptual framework
                  for integrating statistical ideas with human input
                  into AI products and research. These ideas include
                  experimental design principles of randomization and
                  local control as well as the principle of stability
                  to gain reproducibility and interpretability of
                  algorithms and data results. We discuss the use of
                  these principles in the contexts of self-driving
                  cars, automated medical diagnoses, and examples from
                  the authors' collaborative research.},
  archiveprefix = {arXiv},
  eprint = {1712.03779v1},
  primaryclass = {stat.ML}
}
</pre>

<a name="akhtar-2018-threat-adver"></a><pre>
@article{<a href="index.html#akhtar-2018-threat-adver">akhtar-2018-threat-adver</a>,
  author = {Akhtar, Naveed and Mian, Ajmal},
  title = {Threat of Adversarial Attacks on Deep Learning in
                  Computer Vision: A Survey},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.00553v2">http://arxiv.org/abs/1801.00553v2</a>},
  abstract = {Deep learning is at the heart of the current rise of
                  machine learning and artificial intelligence. In the
                  field of Computer Vision, it has become the
                  workhorse for applications ranging from self-driving
                  cars to surveillance and security. Whereas deep
                  neural networks have demonstrated phenomenal success
                  (often beyond human capabilities) in solving complex
                  problems, recent studies show that they are
                  vulnerable to adversarial attacks in the form of
                  subtle perturbations to inputs that lead a model to
                  predict incorrect outputs. For images, such
                  perturbations are often too small to be perceptible,
                  yet they completely fool the deep learning models.
                  Adversarial attacks pose a serious threat to the
                  success of deep learning in practice. This fact has
                  lead to a large influx of contributions in this
                  direction. This article presents the first
                  comprehensive survey on adversarial attacks on deep
                  learning in Computer Vision. We review the works
                  that design adversarial attacks, analyze the
                  existence of such attacks and propose defenses
                  against them. To emphasize that adversarial attacks
                  are possible in practical conditions, we separately
                  review the contributions that evaluate adversarial
                  attacks in the real-world scenarios. Finally, we
                  draw on the literature to provide a broader outlook
                  of the research direction.},
  archiveprefix = {arXiv},
  eprint = {1801.00553},
  primaryclass = {cs.CV}
}
</pre>

<a name="vural-2015-study-class"></a><pre>
@article{<a href="index.html#vural-2015-study-class">vural-2015-study-class</a>,
  author = {Vural, Elif and Guillemot, Christine},
  title = {A Study of the Classification of Low-Dimensional
                  Data With Supervised Manifold Learning},
  journal = {CoRR},
  year = 2015,
  url = {<a href="http://arxiv.org/abs/1507.05880v3">http://arxiv.org/abs/1507.05880v3</a>},
  abstract = {Supervised manifold learning methods learn data
                  representations by preserving the geometric
                  structure of data while enhancing the separation
                  between data samples from different classes. In this
                  work, we propose a theoretical study of supervised
                  manifold learning for classification. We consider
                  nonlinear dimensionality reduction algorithms that
                  yield linearly separable embeddings of training data
                  and present generalization bounds for this type of
                  algorithms. A necessary condition for satisfactory
                  generalization performance is that the embedding
                  allow the construction of a sufficiently regular
                  interpolation function in relation with the
                  separation margin of the embedding. We show that for
                  supervised embeddings satisfying this condition, the
                  classification error decays at an exponential rate
                  with the number of training samples. Finally, we
                  examine the separability of supervised nonlinear
                  embeddings that aim to preserve the low-dimensional
                  geometric structure of data based on graph
                  representations. The proposed analysis is supported
                  by experiments on several real data sets.},
  archiveprefix = {arXiv},
  eprint = {1507.05880},
  primaryclass = {cs.LG}
}
</pre>

<a name="rodriguez-2018-shiel-googl"></a><pre>
@article{<a href="index.html#rodriguez-2018-shiel-googl">rodriguez-2018-shiel-googl</a>,
  author = {Rodriguez, Nestor and Rojas-Galeano, Sergio},
  title = {Shielding Google's Language Toxicity Model Against
                  Adversarial Attacks},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01828v1">http://arxiv.org/abs/1801.01828v1</a>},
  abstract = {Lack of moderation in online communities enables
                  participants to incur in personal aggression,
                  harassment or cyberbullying, issues that have been
                  accentuated by extremist radicalisation in the
                  contemporary post-truth politics scenario. This kind
                  of hostility is usually expressed by means of toxic
                  language, profanity or abusive statements. Recently
                  Google has developed a machine-learning-based
                  toxicity model in an attempt to assess the hostility
                  of a comment; unfortunately, it has been suggested
                  that said model can be deceived by adversarial
                  attacks that manipulate the text sequence of the
                  comment. In this paper we firstly characterise such
                  adversarial attacks as using obfuscation and
                  polarity transformations. The former deceives by
                  corrupting toxic trigger content with typographic
                  edits, whereas the latter deceives by grammatical
                  negation of the toxic content. Then, we propose a
                  two--stage approach to counter--attack these
                  anomalies, bulding upon a recently proposed text
                  deobfuscation method and the toxicity scoring model.
                  Lastly, we conducted an experiment with
                  approximately 24000 distorted comments, showing how
                  in this way it is feasible to restore toxicity of
                  the adversarial variants, while incurring roughly on
                  a twofold increase in processing time. Even though
                  novel adversary challenges would keep coming up
                  derived from the versatile nature of written
                  language, we anticipate that techniques combining
                  machine learning and text pattern recognition
                  methods, each one targeting different layers of
                  linguistic features, would be needed to achieve
                  robust detection of toxic language, thus fostering
                  aggression--free digital interaction.},
  archiveprefix = {arXiv},
  eprint = {1801.01828},
  primaryclass = {cs.CL}
}
</pre>

<a name="contractor-2018-towar-under"></a><pre>
@article{<a href="index.html#contractor-2018-towar-under">contractor-2018-towar-under</a>,
  author = {Contractor, Danish and Patra, Barun and Singla,
                  Mausam and Singla, Parag},
  title = {Towards Understanding and Answering Multi-Sentence
                  Recommendation Questions on Tourism},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01825v1">http://arxiv.org/abs/1801.01825v1</a>},
  abstract = {We introduce the first system towards the novel task
                  of answering complex multisentence recommendation
                  questions in the tourism domain. Our solution uses a
                  pipeline of two modules: question understanding and
                  answering. For question understanding, we define an
                  SQL-like query language that captures the semantic
                  intent of a question; it supports operators like
                  subset, negation, preference and similarity, which
                  are often found in recommendation questions. We
                  train and compare traditional CRFs as well as
                  bidirectional LSTM-based models for converting a
                  question to its semantic representation. We extend
                  these models to a semisupervised setting with
                  partially labeled sequences gathered through
                  crowdsourcing. We find that our best model performs
                  semi-supervised training of BiDiLSTM+CRF with
                  hand-designed features and CCM(Chang et al., 2007)
                  constraints. Finally, in an end to end QA system,
                  our answering component converts our question
                  representation into queries fired on underlying
                  knowledge sources. Our experiments on two different
                  answer corpora demonstrate that our system can
                  significantly outperform baselines with up to 20 pt
                  higher accuracy and 17 pt higher recall.},
  archiveprefix = {arXiv},
  eprint = {1801.01825},
  primaryclass = {cs.CL}
}
</pre>

<a name="florescu-2018-learn-featur"></a><pre>
@article{<a href="index.html#florescu-2018-learn-featur">florescu-2018-learn-featur</a>,
  author = {Florescu, Corina and Jin, Wei},
  title = {Learning Feature Representations for Keyphrase
                  Extraction},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01768v1">http://arxiv.org/abs/1801.01768v1</a>},
  abstract = {In supervised approaches for keyphrase extraction, a
                  candidate phrase is encoded with a set of
                  hand-crafted features and machine learning
                  algorithms are trained to discriminate keyphrases
                  from non-keyphrases. Although the manually-designed
                  features have shown to work well in practice,
                  feature engineering is a difficult process that
                  requires expert knowledge and normally does not
                  generalize well. In this paper, we present SurfKE, a
                  feature learning framework that exploits the text
                  itself to automatically discover patterns that
                  keyphrases exhibit. Our model represents the
                  document as a graph and automatically learns feature
                  representation of phrases. The proposed model
                  obtains remarkable improvements in performance over
                  strong baselines.},
  archiveprefix = {arXiv},
  eprint = {1801.01768},
  primaryclass = {cs.CL}
}
</pre>

<a name="charte-2018-pract-tutor"></a><pre>
@article{<a href="index.html#charte-2018-pract-tutor">charte-2018-pract-tutor</a>,
  author = {Charte, David and Charte, Francisco and Garc{\'i}a,
                  Salvador and Jesus, Mar{\'i}a J. del and Herrera,
                  Francisco},
  title = {A Practical Tutorial on Autoencoders for Nonlinear
                  Feature Fusion: Taxonomy, Models, Software and
                  Guidelines},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01586v1">http://arxiv.org/abs/1801.01586v1</a>},
  abstract = {Many of the existing machine learning algorithms,
                  both supervised and unsupervised, depend on the
                  quality of the input characteristics to generate a
                  good model. The amount of these variables is also
                  important, since performance tends to decline as the
                  input dimensionality increases, hence the interest
                  in using feature fusion techniques, able to produce
                  feature sets that are more compact and higher level.
                  A plethora of procedures to fuse original variables
                  for producing new ones has been developed in the
                  past decades. The most basic ones use linear
                  combinations of the original variables, such as PCA
                  (Principal Component Analysis) and LDA (Linear
                  Discriminant Analysis), while others find manifold
                  embeddings of lower dimensionality based on
                  non-linear combinations, such as Isomap or LLE
                  (Linear Locally Embedding) techniques. More
                  recently, autoencoders (AEs) have emerged as an
                  alternative to manifold learning for conducting
                  nonlinear feature fusion. Dozens of AE models have
                  been proposed lately, each with its own specific
                  traits. Although many of them can be used to
                  generate reduced feature sets through the fusion of
                  the original ones, there also AEs designed with
                  other applications in mind. The goal of this paper
                  is to provide the reader with a broad view of what
                  an AE is, how they are used for feature fusion, a
                  taxonomy gathering a broad range of models, and how
                  they relate to other classical techniques. In
                  addition, a set of didactic guidelines on how to
                  choose the proper AE for a given task is supplied,
                  together with a discussion of the software tools
                  available. Finally, two case studies illustrate the
                  usage of AEs with datasets of handwritten digits and
                  breast cancer.},
  archiveprefix = {arXiv},
  eprint = {1801.01586},
  primaryclass = {cs.LG}
}
</pre>

<a name="poddar-2018-clust-data"></a><pre>
@article{<a href="index.html#poddar-2018-clust-data">poddar-2018-clust-data</a>,
  author = {Poddar, Sunrita and Jacob, Mathews},
  title = {Clustering of Data With Missing Entries},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01455v1">http://arxiv.org/abs/1801.01455v1</a>},
  abstract = {The analysis of large datasets is often complicated
                  by the presence of missing entries, mainly because
                  most of the current machine learning algorithms are
                  designed to work with full data. The main focus of
                  this work is to introduce a clustering algorithm,
                  that will provide good clustering even in the
                  presence of missing data. The proposed technique
                  solves an $\ell_0$ fusion penalty based optimization
                  problem to recover the clusters. We theoretically
                  analyze the conditions needed for the successful
                  recovery of the clusters. We also propose an
                  algorithm to solve a relaxation of this problem
                  using saturating non-convex fusion penalties. The
                  method is demonstrated on simulated and real
                  datasets, and is observed to perform well in the
                  presence of large fractions of missing entries.},
  archiveprefix = {arXiv},
  eprint = {1801.01455},
  primaryclass = {cs.LG}
}
</pre>

<a name="weatherall-2018-how-to"></a><pre>
@article{<a href="index.html#weatherall-2018-how-to">weatherall-2018-how-to</a>,
  author = {Weatherall, James Owen and O'Connor, Cailin and
                  Bruner, Justin},
  title = {How To Beat Science and Influence People: Policy
                  Makers and Propaganda in Epistemic Networks},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01239v1">http://arxiv.org/abs/1801.01239v1</a>},
  abstract = {In their recent book Merchants of Doubt [New
                  York:Bloomsbury 2010], Naomi Oreskes and Erik Conway
                  describe the "tobacco strategy", which was used by
                  the tobacco industry to influence policy makers
                  regarding the health risks of tobacco products. The
                  strategy involved two parts, consisting of (1)
                  promoting and sharing independent research
                  supporting the industry's preferred position and (2)
                  funding additional research, but selectively
                  publishing the results. We introduce a model of the
                  Tobacco Strategy, and use it to argue that both
                  prongs of the strategy can be extremely
                  effective--even when policy makers rationally update
                  on all evidence available to them. As we elaborate,
                  this model helps illustrate the conditions under
                  which the Tobacco Strategy is particularly
                  successful. In addition, we show how journalists
                  engaged in "fair" reporting can inadvertently mimic
                  the effects of industry on public belief.},
  archiveprefix = {arXiv},
  eprint = {1801.01239},
  primaryclass = {cs.SI}
}
</pre>

<a name="lipp-2018-meltd"></a><pre>
@article{<a href="index.html#lipp-2018-meltd">lipp-2018-meltd</a>,
  author = {Lipp, Moritz and Schwarz, Michael and Gruss, Daniel
                  and Prescher, Thomas and Haas, Werner and Mangard,
                  Stefan and Kocher, Paul and Genkin, Daniel and
                  Yarom, Yuval and Hamburg, Mike},
  title = {Meltdown},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01207v1">http://arxiv.org/abs/1801.01207v1</a>},
  abstract = {The security of computer systems fundamentally
                  relies on memory isolation, e.g., kernel address
                  ranges are marked as non-accessible and are
                  protected from user access. In this paper, we
                  present Meltdown. Meltdown exploits side effects of
                  out-of-order execution on modern processors to read
                  arbitrary kernel-memory locations including personal
                  data and passwords. Out-of-order execution is an
                  indispensable performance feature and present in a
                  wide range of modern processors. The attack works on
                  different Intel microarchitectures since at least
                  2010 and potentially other processors are affected.
                  The root cause of Meltdown is the hardware. The
                  attack is independent of the operating system, and
                  it does not rely on any software vulnerabilities.
                  Meltdown breaks all security assumptions given by
                  address space isolation as well as paravirtualized
                  environments and, thus, every security mechanism
                  building upon this foundation. On affected systems,
                  Meltdown enables an adversary to read memory of
                  other processes or virtual machines in the cloud
                  without any permissions or privileges, affecting
                  millions of customers and virtually every user of a
                  personal computer. We show that the KAISER defense
                  mechanism for KASLR has the important (but
                  inadvertent) side effect of impeding Meltdown. We
                  stress that KAISER must be deployed immediately to
                  prevent large-scale exploitation of this severe
                  information leakage.},
  archiveprefix = {arXiv},
  eprint = {1801.01207},
  primaryclass = {cs.CR}
}
</pre>

<a name="kocher-2018-spect-attac"></a><pre>
@article{<a href="index.html#kocher-2018-spect-attac">kocher-2018-spect-attac</a>,
  author = {Kocher, Paul and Genkin, Daniel and Gruss, Daniel
                  and Haas, Werner and Hamburg, Mike and Lipp, Moritz
                  and Mangard, Stefan and Prescher, Thomas and
                  Schwarz, Michael and Yarom, Yuval},
  title = {Spectre Attacks: Exploiting Speculative Execution},
  journal = {CoRR},
  year = 2018,
  url = {<a href="http://arxiv.org/abs/1801.01203v1">http://arxiv.org/abs/1801.01203v1</a>},
  abstract = {Modern processors use branch prediction and
                  speculative execution to maximize performance. For
                  example, if the destination of a branch depends on a
                  memory value that is in the process of being read,
                  CPUs will try guess the destination and attempt to
                  execute ahead. When the memory value finally
                  arrives, the CPU either discards or commits the
                  speculative computation. Speculative logic is
                  unfaithful in how it executes, can access to the
                  victim's memory and registers, and can perform
                  operations with measurable side effects. Spectre
                  attacks involve inducing a victim to speculatively
                  perform operations that would not occur during
                  correct program execution and which leak the
                  victim's confidential information via a side channel
                  to the adversary. This paper describes practical
                  attacks that combine methodology from side channel
                  attacks, fault attacks, and return-oriented
                  programming that can read arbitrary memory from the
                  victim's process. More broadly, the paper shows that
                  speculative execution implementations violate the
                  security assumptions underpinning numerous software
                  security mechanisms, including operating system
                  process separation, static analysis,
                  containerization, just-in-time (JIT) compilation,
                  and countermeasures to cache timing/side-channel
                  attacks. These attacks represent a serious threat to
                  actual systems, since vulnerable speculative
                  execution capabilities are found in microprocessors
                  from Intel, AMD, and ARM that are used in billions
                  of devices. While makeshift processor-specific
                  countermeasures are possible in some cases, sound
                  solutions will require fixes to processor designs as
                  well as updates to instruction set architectures
                  (ISAs) to give hardware architects and software
                  developers a common understanding as to what
                  computation state CPU implementations are (and are
                  not) permitted to leak.},
  archiveprefix = {arXiv},
  eprint = {1801.01203},
  primaryclass = {cs.CR}
}
</pre>

<a name="lake-2016-build-machin"></a><pre>
@article{<a href="index.html#lake-2016-build-machin">lake-2016-build-machin</a>,
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum,
                  Joshua B. and Gershman, Samuel J.},
  title = {Building Machines That Learn and Think Like People},
  journal = {CoRR},
  year = 2016,
  url = {<a href="http://arxiv.org/abs/1604.00289v3">http://arxiv.org/abs/1604.00289v3</a>},
  abstract = {Recent progress in artificial intelligence (AI) has
                  renewed interest in building systems that learn and
                  think like people. Many advances have come from
                  using deep neural networks trained end-to-end in
                  tasks such as object recognition, video games, and
                  board games, achieving performance that equals or
                  even beats humans in some respects. Despite their
                  biological inspiration and performance achievements,
                  these systems differ from human intelligence in
                  crucial ways. We review progress in cognitive
                  science suggesting that truly human-like learning
                  and thinking machines will have to reach beyond
                  current engineering trends in both what they learn,
                  and how they learn it. Specifically, we argue that
                  these machines should (a) build causal models of the
                  world that support explanation and understanding,
                  rather than merely solving pattern recognition
                  problems; (b) ground learning in intuitive theories
                  of physics and psychology, to support and enrich the
                  knowledge that is learned; and (c) harness
                  compositionality and learning-to-learn to rapidly
                  acquire and generalize knowledge to new tasks and
                  situations. We suggest concrete challenges and
                  promising routes towards these goals that can
                  combine the strengths of recent neural network
                  advances with more structured cognitive models.},
  archiveprefix = {arXiv},
  eprint = {1604.00289},
  primaryclass = {cs.AI}
}
</pre>

<a name="foster-2017-param-free"></a><pre>
@article{<a href="index.html#foster-2017-param-free">foster-2017-param-free</a>,
  author = {Foster, Dylan J. and Kale, Satyen and Mohri, Mehryar
                  and Sridharan, Karthik},
  title = {Parameter-Free Online Learning Via Model Selection},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1801.00101v2">http://arxiv.org/abs/1801.00101v2</a>},
  abstract = {We introduce an efficient algorithmic framework for
                  model selection in online learning, also known as
                  parameter-free online learning. Departing from
                  previous work, which has focused on highly
                  structured function classes such as nested balls in
                  Hilbert space, we propose a generic meta-algorithm
                  framework that achieves online model selection
                  oracle inequalities under minimal structural
                  assumptions. We give the first computationally
                  efficient parameter-free algorithms that work in
                  arbitrary Banach spaces under mild smoothness
                  assumptions; previous results applied only to
                  Hilbert spaces. We further derive new oracle
                  inequalities for matrix classes, non-nested convex
                  sets, and $\mathbb{R}^{d}$ with generic
                  regularizers. Finally, we generalize these results
                  by providing oracle inequalities for arbitrary
                  non-linear classes in the online supervised learning
                  model. These results are all derived through a
                  unified meta-algorithm scheme using a novel
                  "multi-scale" algorithm for prediction with expert
                  advice based on random playout, which may be of
                  independent interest.},
  archiveprefix = {arXiv},
  eprint = {1801.00101v2},
  primaryclass = {cs.LG}
}
</pre>

<a name="weber-2017-imagin-augmen"></a><pre>
@article{<a href="index.html#weber-2017-imagin-augmen">weber-2017-imagin-augmen</a>,
  author = {Weber, Th{\'e}ophane and Racani{\`e}re,
                  S{\'e}bastien and Reichert, David P. and Buesing,
                  Lars and Guez, Arthur and Rezende, Danilo Jimenez
                  and Badia, Adria Puigdom{\`e}nech and Vinyals, Oriol
                  and Heess, Nicolas and Li, Yujia and Pascanu, Razvan
                  and Battaglia, Peter and Silver, David and Wierstra,
                  Daan},
  title = {Imagination-Augmented Agents for Deep Reinforcement
                  Learning},
  journal = {CoRR},
  year = 2017,
  url = {<a href="http://arxiv.org/abs/1707.06203v1">http://arxiv.org/abs/1707.06203v1</a>},
  abstract = {We introduce Imagination-Augmented Agents (I2As), a
                  novel architecture for deep reinforcement learning
                  combining model-free and model-based aspects. In
                  contrast to most existing model-based reinforcement
                  learning and planning methods, which prescribe how a
                  model should be used to arrive at a policy, I2As
                  learn to interpret predictions from a learned
                  environment model to construct implicit plans in
                  arbitrary ways, by using the predictions as
                  additional context in deep policy networks. I2As
                  show improved data efficiency, performance, and
                  robustness to model misspecification compared to
                  several baselines.},
  archiveprefix = {arXiv},
  eprint = {1707.06203},
  primaryclass = {cs.LG}
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
</body>
</html>
